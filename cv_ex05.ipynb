{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEQF3J2fb6RN"
   },
   "source": [
    "第5回の演習です。ここでは、外部モジュールOpenCVの基本を説明します。\n",
    "左上の「ファイル」＞「ドライブにコピーを保存」を選択して、Google DriveにNotebookを保存します。ご自身のGoogleドライブの\"Colab Notebooks\"フォルダで、保存したNotebookを右クリックし、「アプリで開く」＞「Google Colaboratory」を選択します。その上で、各コードを実行するには、以下のコマンドを実行してください。実行は「再生」ボタンを押します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arnzzHVKbsJ_",
    "outputId": "b186cd44-af76-421f-9c2b-2ddf562bc30d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Chapter 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONboX2zZ4YBh"
   },
   "source": [
    "# OpenCV\n",
    "OpenCVはオープンソースの画像処理ライブラリで、コンピュータで画像を処理したり機械学習したりする機能を提供します。その機能は多様で高度であり、深層学習の画像データを前処理するのに大変有用です。元々、Intelが開発したもので、正式名称はOpen Source Computer Vision Libraryです。この演習で示されるプログラムコードは基本的に、[OpenCVのWebサイト](https://opencv.org/)で示されているデモやチュートリアルをベースにしています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYdfgp5c4dK4"
   },
   "source": [
    "## 画像ファイルの用意\n",
    "まず、OpenCVでの処理に使う画像を用意します。画像はどんなものでもよいのですが、ファイルサイズがあまり大きいと、その後の処理が重たくなるかも知れません。適当な画像ファイルがない、という方はココ([manapi02.png](https://drive.google.com/file/d/1GJfBAoxRyoEcxCnIp87VUL9KWqdUeeLT/view?usp=sharing))からダウンロードして下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZhHiy8K4goJ"
   },
   "source": [
    "画像をファイルとしてGoogle Colaboratory上にアップロードしますので、そのためのfilesモジュールをインポートします。「ファイル選択」というボタンが表示されますので、これをクリックしてアップロードする画像ファイルを選択します。注意点は、アップロードしたデータは永久保存されないということです。Notebookの実行環境がリセットされると、アップロードしたデータは消えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "id": "DfKfy-CM4jrZ",
    "outputId": "9fd68154-33f5-46ff-ed32-0f815a6d9d4f"
   },
   "outputs": [],
   "source": [
    "# ローカル環境では直接画像ファイルを指定\n",
    "import os\n",
    "image_filename = \"example.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1paZJt0O4mjg"
   },
   "source": [
    "適切にアップロードされたら、「...100% done, Saving ファイル名 to ファイル名」といったメッセージが出ます。アップロードされたファイルを確認するには、以下のコマンドを使ってファイルを表示してみます。type関数は、変数の型を調べるのでした。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdVjAfuz4piR",
    "outputId": "c2a6929f-178d-4764-ee9c-b403e0d30424"
   },
   "outputs": [],
   "source": [
    "# ローカル環境では不要\n",
    "print(f\"使用する画像ファイル: {image_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4ouEEdk4tJR"
   },
   "source": [
    "\"dict_items\"の後に、（ファイル名, データ）という形式でデータが表示されていると想定されます。<class 'dict_items'>と表示されているのは、画像ファイルが辞書型になっているという意味です。辞書は、キーと値を組み合わせたリストです。キーを参照することで、辞書から値を抽出することができます。' 'の前についている\"b\"は、このデータがバイナリデータであることを示しています。上記のitemsメソッドは、辞書のキーと値の対(key, value)を返します。keysメソッドは辞書のキーの一覧を返します。valuesメソッドは値の一覧を返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9BmZMWM74v7x",
    "outputId": "b0999f28-ce83-4ab2-b9ad-de4ca347ef9e"
   },
   "outputs": [],
   "source": [
    "# ローカル環境では不要\n",
    "print(f\"ファイルが存在するか確認: {os.path.exists(image_filename)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0t3uiyh4zLJ"
   },
   "source": [
    "次に、ファイル名を取得し、OpenCVでこの画像ファイルを読み込めるようにします。\n",
    "画像のファイル名は辞書のキーに入っていますから、keysメソッドでこれを取り出します。このままだと、取り出したキーの変数も辞書型になりますから、list関数で辞書型をリスト型に変換します。その上で、リストの最初の要素（行）を取り出し、ファイル名とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIvE9FcC42yB",
    "outputId": "8830ffe9-e47c-422d-d75b-1891f5b3de53"
   },
   "outputs": [],
   "source": [
    "# 画像のファイル名を確認\n",
    "print(f\"使用する画像ファイル: {image_filename}\")\n",
    "print(f\"ファイルパス: {os.path.abspath(image_filename)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnI1mHJu45wB"
   },
   "source": [
    "## OpenCVの準備\n",
    "次に、OpenCVをインポートして、OpenCVを使うための準備を行います。OpenCVで読み込んだ画像データを配列として扱うために、NumPyを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4C4zI_8m48rR"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# OpenCVを使う準備\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# OpenCVを使う準備\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NOJkmJv4_h5"
   },
   "source": [
    "画像ファイルを読み込むには、imread関数を使います。また、読み込んだ画像ファイルを表示するには、OpenCVのimshow関数を使います。このimshow関数は、BGRデータを画像に変換する働きがあります。画像として描画する用意をするだけなのですが、ここではGoogle ColaboratoryのNotebook上に画像を表示したいので、Google Colaboratoryから提供されるモジュールを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6c2pvdf5C1Z",
    "outputId": "f5194d43-ab07-46c6-96a7-a32032bafd08"
   },
   "outputs": [],
   "source": [
    "cv_img = cv2.imread(image_filename)\n",
    "\n",
    "# ローカル環境ではmatplotlibを使用して画像表示する関数を定義\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(img, title=\"Image\", cmap=None):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if len(img.shape) == 3:\n",
    "        # カラー画像の場合、BGR→RGB変換\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        # グレースケール画像の場合\n",
    "        plt.imshow(img, cmap='gray' if cmap is None else cmap)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_image(cv_img, \"Original Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jC6ci5lA5F-Y"
   },
   "source": [
    "画像が表示されました。ここで、画像の生データを確認してみましょう。[255, 255, 255]といった配列が多数並んでいることがわかります。この配列は、画像上の画素の画素値をBGRごとに表しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9Z-945E5IYp",
    "outputId": "5d59b37a-88bb-4e09-84be-c7ff01c397b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "print(len(cv_img))\n",
    "print(cv_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAKmYJTL5Lqy"
   },
   "source": [
    "## 画像データの解析\n",
    "ここで、もう少し画像の生データを調べて、画像に変更を加えていきましょう。実は、読み込まれた画像データはNumPy配列ndarrayになっています。画像データの型をtype関数で確認しましょう。次に、配列の形状を求め、その構造を確認します。shapeメソッドの実行結果は（縦のデータ数、横のデータ数、色のチャネル数）を表します。それと、OpenCVの画像データでは色の成分がRGBではなく、BGRになっています。配列の0番目（B：青）と1番目（G：緑）を\"0\"（黒）に設定して確認しましょう。ここで、スライスの記号\":\"はすべての要素を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0AOY4PN5OYA",
    "outputId": "11c10a93-d256-47c7-e546-fa0194a17f01"
   },
   "outputs": [],
   "source": [
    "# 画像データの型・形状\n",
    "print(type(cv_img))           # 型\n",
    "print(cv_img.shape)           # 形状\n",
    "# 色の青成分と緑成分を\"0\"に設定\n",
    "x = np.array(cv_img)\n",
    "x[:, :, (0, 1)] = 0           # 赤成分だけを残す\n",
    "show_image(x, \"Red Channel Only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfrj6a_I5R_I"
   },
   "source": [
    "では、色のBGR（青緑赤）表現をグレースケールの表現に変換すると、どうなるでしょう。cvtColor関数は、画像データの色調を変換する機能があります。第1引数に画像データを、第2引数にCOLOR_BGR2GRAY（グレースケールへの変換）を設定しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPRqjCQQ5VBw",
    "outputId": "700e535d-4549-4dd8-bc6c-1dcb57cbc5b2"
   },
   "outputs": [],
   "source": [
    "# RGBデータをグレースケールのデータに変換\n",
    "img_gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)\n",
    "show_image(img_gray, \"Grayscale Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b8r8eZK5Y-6"
   },
   "source": [
    "ここで、一旦、グレースケールに変換した画像データをファイルとして保存しておきましょう。画像を保存するための関数はimwrite（ファイル名, 画像データ）です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nIUuf35Y5crS",
    "outputId": "470b6e3d-bf00-4099-9ef5-77643be9ac7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 画像の保存\n",
    "cv2.imwrite(\"manapi_gray.png\", img_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZHjuD7c5gcx"
   },
   "source": [
    "\"True\"と表示されれば、画像ファイルの保存は成功です。と、画像ファイルはどこに保存されたのでしょうか。実は、Google Colaboratory上にあります。サイドバーの「フォルダ」アイコンをクリックすると、Google Colaboratory上にあるファイルの一覧を確認できます。「画像ファイルの用意」で書きましたように、Google Colaboratory上のデータは永久保存されず、Notebookの実行環境がリセットされれば、これらのデータは消えます。そこで、自身のコンピュータにダウンロードしておきます。やり方は、ファイル名のところにマウス・カーソルを持っていき、右側に表示される「：」を左クリックし、「ダウンロード」を選択します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr__4qSW5qpY"
   },
   "source": [
    "# 画像の加工\n",
    "ここからは、画像を加工する機能を色々と見ていくことにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4TctiVt5kbh"
   },
   "source": [
    "## 切り抜き（トリミング）\n",
    "まずは、画像の一部分を切り出します。画像の不要部分を切り取って、必要な部分を抜き出す処理をトリミングと言います。ここでは、画像の縦と横のサイズをそれぞれ半分のところで切り落とすことにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQA65or-5uko",
    "outputId": "8830a651-1635-44b4-a9f7-47052f6520da"
   },
   "outputs": [],
   "source": [
    "# 画像の切り抜き\n",
    "size = cv_img.shape                             # 画像データの形状を取得\n",
    "img = cv_img[:size[0] // 2, :size[1] // 2]      # size[0]は縦の画素数、size[1]は横の画素数\n",
    "print(\"切り抜き処理後の画像の形状\", img.shape)\n",
    "show_image(img, \"Cropped Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kY0iyb5Y50qY"
   },
   "source": [
    "## 拡大・縮小\n",
    "画像を拡大あるいは縮小し、画像のサイズを変更します。例えば、画像を拡大する場合、画像データの配列を増やしますので、データ容量は増加します。resize関数を使います。引数は、（画像データ, dsize =（横の画素数, 縦の画素数））のように設定します。注意点は、引数dsizeの画素数を（横・縦）の順に指定することです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cFhkMaehYUMF",
    "outputId": "cff8816d-0eed-40f4-bddb-27bdb6d19d44"
   },
   "outputs": [],
   "source": [
    "size = cv_img.shape                             # 画像の形状（縦横の画素数）を取得\n",
    "print(\"元の画像の形状\", size)\n",
    "size_img = cv2.resize(cv_img, dsize = (size[1] * 2, size[0] * 2))\n",
    "print(\"拡大画像の形状\", size_img.shape)         # 拡大した後の画像のサイズを取得\n",
    "show_image(size_img, \"Enlarged Image (2x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCCIT4jzbInm"
   },
   "source": [
    "次に、画像を縮小してみましょう。画像を縮小する場合、画像データの配列を減らしますので、データ容量は減少します。ここでもresize関数を使います。引数は、画像の拡大のときと同じように設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKRrZQIVcZlW",
    "outputId": "d6439c70-84fb-4f5c-b76e-54814370be8c"
   },
   "outputs": [],
   "source": [
    "size = cv_img.shape                             # 画像の形状（縦横の画素数）を取得\n",
    "print(\"元の画像の形状\", size)\n",
    "size_img = cv2.resize(cv_img, dsize = (size[1] // 10, size[0] // 10))\n",
    "print(\"縮小画像の形状\", size_img.shape)         # 縮小した後の画像のサイズを取得\n",
    "show_image(size_img, \"Reduced Image (1/10x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhaooPJscJaK"
   },
   "source": [
    "## 画像の回転\n",
    "次に、画像を回転してみましょう。画像を回転するにはwarpAffine関数を使います。warpAffine関数はアフィン変換を行い、その引数に（画像データ, M, dsize）を指定します。2番目の引数Mは変換行列、3番目の引数dsizeは画像のサイズを指定します。変換行列はNumPy配列で与え、getRotationMatrix2D関数で生成することができます。この関数の引数に（回転中心, 回転角, 拡大・縮小の倍率）を指定します。回転角はradianではなく、角度で与えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BsQX0MsxcF0L",
    "outputId": "d28f8567-02a7-45f8-e488-6d405c84f7b8"
   },
   "outputs": [],
   "source": [
    "# 画像の回転（45度）\n",
    "h, w, ch = cv_img.shape                                       # 画像データの形状（縦, 横, 色のチャネル数）\n",
    "print(h, w, ch)\n",
    "mat = cv2.getRotationMatrix2D((w / 2, h / 2), 45, 1.0)        # 変換行列（回転中心は画像の中心位置）\n",
    "rot_img = cv2.warpAffine(cv_img, mat, (w, h))                 # アフィン変換\n",
    "show_image(rot_img, \"Rotated Image (45°)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uykyPCOn0BfU"
   },
   "source": [
    "画像は回転しましたが、画像の四隅が欠けてしまったと想定されます。これだと情報が失われることになりますから、機械学習の学習データとして使うことを考えると好ましいことではありません。getRotation Matrix2Dの引数を変更し、画像を縮小します。ついでに回転角度も変えてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0FXq3SKM1n8s",
    "outputId": "abdeb196-2c20-4319-b09d-45e1eb88a3da"
   },
   "outputs": [],
   "source": [
    "# 画像の回転（-45度）\n",
    "h, w, ch = cv_img.shape                                       # 画像データの形状（縦, 横, 色のチャネル数）\n",
    "print(h, w, ch)\n",
    "mat = cv2.getRotationMatrix2D((w / 2, h / 2), -45, 0.5)       # 変換行列（回転中心は画像の中心位置）\n",
    "rot_img = cv2.warpAffine(cv_img, mat, (w, h))                 # アフィン変換\n",
    "show_image(rot_img, \"Rotated Image (-45°, 0.5x scale)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQyakkWJ208s"
   },
   "source": [
    "warpAffine関数の引数にflagsを指定すると、補間処理が働きます。ここでは詳しく説明しませんが、画像を回転すると、元の画像と回転した画像とで画素の中心がズレるという現象が発生します。この影響を抑えるため、補間処理を行います。ただ、画像の解像度が高いときは、見た目にあまり違いはないかも知れません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4rxnT_F31n8",
    "outputId": "9ae27103-2d3b-46ca-faac-4c60bf4f7f78"
   },
   "outputs": [],
   "source": [
    "# 画像の回転（補間処理：bicubic）\n",
    "h, w, ch = cv_img.shape                                       # 画像データの形状（縦, 横, 色のチャネル数）\n",
    "print(h, w, ch)\n",
    "mat = cv2.getRotationMatrix2D((w / 2, h / 2), -45, 0.5)       # 変換行列（回転中心は画像の中心位置）\n",
    "rot_img = cv2.warpAffine(cv_img, mat, (w, h), flags=cv2.INTER_CUBIC)                 # アフィン変換（bicubic補間）\n",
    "show_image(rot_img, \"Rotated Image with Bicubic Interpolation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wiz5kQJR4rTs"
   },
   "source": [
    "画像を回転して気になる点は、画像以外の領域の扱いです。これまでは何も処理していませんから、真っ黒になっていました。warpAffine関数の引数にboaderModeを設定すると、領域外を埋めることができます。引数boaderModeにcv2.BORDER_CONSTANTを指定すると固定値になり、その値は引数borderValueで指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aiHV42OD6hLj",
    "outputId": "c33bbeb3-fd85-48c9-e0aa-098d1c5a1cfe"
   },
   "outputs": [],
   "source": [
    "# 画像の回転（領域外処理：一様な色）\n",
    "h, w, ch = cv_img.shape                                       # 画像データの形状（縦, 横, 色のチャネル数）\n",
    "print(h, w, ch)\n",
    "mat = cv2.getRotationMatrix2D((w / 2, h / 2), -45, 0.5)       # 変換行列（回転中心は画像の中心位置）\n",
    "rot_img = cv2.warpAffine(cv_img, mat, (w, h), flags=cv2.INTER_CUBIC,                    # アフィン変換（bicubic補間）\n",
    "                         borderMode = cv2.BORDER_CONSTANT, borderValue=(255, 255, 0))   # 領域外処理（BGR）\n",
    "show_image(rot_img, \"Rotated Image with Constant Border Fill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCT270z68n4k"
   },
   "source": [
    "引数borderModeにcv2.BORDER_TRANSPARENTを指定すると、別の画像が背景に設定されます。引数dstで背景画像を設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FtsMT_De9G-6",
    "outputId": "d09fd840-9725-48eb-f0dc-0bc58665a950"
   },
   "outputs": [],
   "source": [
    "# 画像の回転（領域外処理：背景画像）\n",
    "h, w, ch = cv_img.shape                                       # 画像データの形状（縦, 横, 色のチャネル数）\n",
    "print(h, w, ch)\n",
    "mat = cv2.getRotationMatrix2D((w / 2, h / 2), -45, 0.5)       # 変換行列（回転中心は画像の中心位置）\n",
    "dst1 = cv_img // 4\n",
    "rot_img = cv2.warpAffine(cv_img, mat, (w, h), flags=cv2.INTER_CUBIC,                # アフィン変換（bicubic補間）\n",
    "                         borderMode = cv2.BORDER_TRANSPARENT, dst = dst1)           # 領域外処理（背景画像）\n",
    "show_image(rot_img, \"Rotated Image with Background Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pwa1GWQI9GNA"
   },
   "source": [
    "引数borderModeにBORDER_WRAPを指定すると、領域外に画像が繰り返し表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-K29nWLg-qAD",
    "outputId": "d6002666-7f74-46a8-d8e2-c8e951c94424"
   },
   "outputs": [],
   "source": [
    "# 画像の回転（領域外処理：繰り返し）\n",
    "h, w, ch = cv_img.shape                                       # 画像データの形状（縦, 横, 色のチャネル数）\n",
    "print(h, w, ch)\n",
    "mat = cv2.getRotationMatrix2D((w / 2, h / 2), -45, 0.5)       # 変換行列（回転中心は画像の中心位置）\n",
    "dst1 = cv_img // 4\n",
    "rot_img = cv2.warpAffine(cv_img, mat, (w, h), flags=cv2.INTER_CUBIC,         # アフィン変換（bicubic補間）\n",
    "                         borderMode = cv2.BORDER_WRAP)                       # 領域外処理（繰り返し）\n",
    "show_image(rot_img, \"Rotated Image with Wrap Border Mode\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
