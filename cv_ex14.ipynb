{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEQF3J2fb6RN"
   },
   "source": [
    "第14回の演習です。CNN（畳み込みニューラルネットワーク）を実装します。\n",
    "左上の「ファイル」＞「ドライブにコピーを保存」を選択して、Google DriveにNotebookを保存します。ご自身のGoogleドライブの\"Colab Notebooks\"フォルダで、保存したNotebookを右クリックし、「アプリで開く」＞「Google Colaboratory」を選択します。その上で、各コードを実行するには、以下のコマンドを実行してください。実行は「再生」ボタンを押します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arnzzHVKbsJ_",
    "outputId": "c05e5b02-ca20-4a65-db71-5dc86b4fdd9e"
   },
   "outputs": [],
   "source": [
    "print(\"Chapter 14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhaooPJscJaK"
   },
   "source": [
    "# CNN\n",
    "前回、Kerasでニューラルネットワークを構築し、Fashion-MNISTデータセットのアイテム画像を認識するというタスクに対してハイパーパラメータを調整しました。その正確度（識別率）は約86%まで改善しましたが、まだ、scikit-learnライブラリのニューラルネットワークのそれには及びません。ここで、畳み込み処理とプーリング処理を導入し、CNNを構築します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wcXQZLm2Zo0"
   },
   "source": [
    "## GPUの利用\n",
    "時間がかかるので、GPUを使います。Coogle Colaboratoryのメニュー「ランライム」をクリックし、「ランタイムのタイプを変更」を選択します。「ハードウェアアクセラレータ」を\"GPU\"に変更します。これで計算処理が多少速く終了するようになるでしょう。ただ、「Colabでの使用量上限に達したため、現在GPUに接続できません」というメッセージが出ると、GPUが割り当てられないこともあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 22:42:06.602655: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750167726.650284   19261 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750167726.664309   19261 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750167726.762597   19261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750167726.762622   19261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750167726.762625   19261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750167726.762629   19261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-17 22:42:06.775026: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1750167730.255478   19261 gpu_device.cc:2019] Created device /device:GPU:0 with 10249 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:04:00.0, compute capability: 8.6\n",
      "I0000 00:00:1750167730.256796   19261 gpu_device.cc:2019] Created device /device:GPU:1 with 1661 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 17933342873726902293\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10747183104\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 10377881929061075142\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:04:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419,\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 1742602240\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 12979894330157390240\n",
       " physical_device_desc: \"device: 1, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
       " xla_global_id: 2144165316]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLp9qVn32wIb"
   },
   "source": [
    "## データセットの用意と前処理\n",
    "まずはデータセットを用意し、前処理を済ませます。これらはこの回では共通の操作ですので、一度実行しておけばよいでしょう。ただし、「ランタイムリセット」されてしまったら再実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSo8nxtL2xEa",
    "outputId": "f05e195f-0ee7-4810-a41b-f2497de3092d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "uint8 uint8\n",
      "(10000, 28, 28) (1000, 28, 28)\n",
      "float32 float32\n",
      "(10000, 28, 28) (1000, 28, 28)\n",
      "学習用データ\n",
      "0.0 - 1.0\n",
      "0 - 9\n",
      "検証用データ\n",
      "0.0 - 1.0\n",
      "0 - 9\n",
      "学習用 [9 0 0 ... 0 6 6] 10000\n",
      "検証用 [8 7 6 8 7 7 2 0 5 3 5 5 1 3 9 4 1 9 3 2 8 2 9 3 4 5 1 0 3 2 8 5 3 8 2 2 9\n",
      " 7 7 9 9 1 2 6 7 6 6 6 6 7 3 7 8 5 9 5 9 1 5 9 8 3 6 1 1 0 3 3 1 2 9 8 9 5\n",
      " 1 0 6 2 3 0 0 8 8 5 7 3 6 9 7 3 6 4 8 5 0 8 3 6 7 1 5 1 7 6 4 1 6 9 8 1 1\n",
      " 7 7 0 7 4 9 4 2 9 9 9 6 5 2 3 5 6 5 1 9 6 1 5 6 9 3 5 3 5 3 2 7 0 9 1 1 2\n",
      " 1 3 6 4 8 4 1 3 2 6 2 0 9 5 8 6 5 5 6 8 0 8 3 9 6 9 8 3 2 5 8 3 9 0 9 9 8\n",
      " 1 3 8 4 9 9 0 3 0 0 6 7 8 6 6 4 6 3 9 0 4 6 7 2 5 6 2 9 7 0 2 2 3 8 4 7 6\n",
      " 8 7 3 6 2 1 3 7 0 4 7 7 5 9 4 9 4 7 1 5 4 6 2 7 1 6 1 4 5 5 8 2 9 9 9 4 7\n",
      " 7 5 2 0 9 1 5 0 4 9 6 8 8 3 3 6 2 6 4 5 8 0 5 2 3 4 9 2 8 5 7 4 4 0 5 3 5\n",
      " 3 5 3 0 0 4 5 0 1 7 6 7 9 0 8 1 4 9 0 6 9 8 8 9 2 9 3 4 2 2 5 9 9 4 1 9 4\n",
      " 4 5 1 9 2 6 1 2 5 7 3 9 9 2 2 7 1 5 0 9 6 6 4 5 4 4 1 1 6 8 0 7 9 2 3 0 8\n",
      " 7 3 2 2 5 3 5 5 0 8 1 4 5 1 8 6 1 1 0 1 5 1 9 5 9 1 0 4 9 5 9 2 6 3 7 7 3\n",
      " 7 2 8 1 5 0 2 8 3 6 6 1 0 8 1 3 5 5 1 4 8 9 3 0 3 3 5 6 4 6 1 3 0 0 7 5 2\n",
      " 9 2 8 0 4 2 2 0 7 9 7 7 6 4 0 3 3 6 2 0 4 5 8 1 3 5 9 6 6 0 6 5 8 8 4 7 6\n",
      " 2 7 3 4 1 5 8 5 5 2 8 3 3 0 7 8 4 1 4 3 1 3 8 1 9 3 4 9 8 0 6 1 1 4 4 5 3\n",
      " 2 4 0 7 9 2 4 9 9 9 0 7 1 3 7 4 3 4 3 1 3 5 1 9 1 7 3 3 8 3 8 4 9 1 0 1 2\n",
      " 5 3 9 7 4 6 0 0 2 2 3 1 3 0 1 2 9 7 1 0 5 1 9 1 3 5 8 7 4 8 4 5 6 3 7 5 7\n",
      " 3 8 1 4 7 5 2 0 4 2 8 7 7 4 9 2 3 6 9 6 7 3 5 2 9 9 2 6 0 6 6 4 7 3 5 7 2\n",
      " 0 0 6 9 6 1 3 0 4 2 1 3 4 9 5 9 4 8 0 5 8 8 0 4 6 2 0 4 7 8 8 4 7 7 4 5 5\n",
      " 4 1 7 9 4 1 8 5 3 3 0 5 7 9 7 1 0 2 6 5 2 5 9 9 2 1 9 5 6 8 2 5 5 0 3 6 4\n",
      " 0 1 6 2 5 5 7 7 6 8 2 6 7 1 7 9 2 9 3 8 8 8 0 9 0 6 3 1 1 9 6 9 2 9 5 9 9\n",
      " 9 2 8 3 6 8 6 5 8 9 5 6 3 7 8 7 5 8 7 6 3 7 2 9 8 0 2 1 0 6 1 6 5 6 4 2 8\n",
      " 1 9 2 9 5 6 4 8 2 3 9 4 3 3 9 0 1 5 6 4 6 5 3 3 6 7 9 7 1 3 7 8 4 8 4 3 6\n",
      " 6 4 4 3 2 4 4 9 7 5 9 9 3 0 2 6 7 6 8 0 2 2 9 6 0 1 9 3 3 9 0 9 1 4 5 4 4\n",
      " 9 7 8 7 5 0 4 4 8 8 5 7 4 8 9 3 9 4 6 7 8 9 0 5 6 2 2 3 5 4 4 3 7 8 2 5 6\n",
      " 6 1 8 7 2 4 2 8 4 0 2 2 7 4 0 9 9 1 3 5 4 7 3 8 5 3 6 9 6 1 9 7 0 4 0 8 2\n",
      " 7 6 6 0 4 8 6 2 5 8 4 7 0 8 2 3 8 8 3 6 4 2 5 0 0 5 1 9 8 5 8 8 7 3 5 9 8\n",
      " 2 1 9 2 3 4 8 3 6 8 0 7 3 6 6 7 3 8 1 0 1 4 0 2 0 8 8 7 8 6 5 6 9 6 9 2 5\n",
      " 5] 1000\n",
      "学習用 [[0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] 10000\n",
      "検証用 [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] 1000\n"
     ]
    }
   ],
   "source": [
    "# Fashion-MNISTデータセット\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(train_data, train_label), (test_data, test_label) = fashion_mnist.load_data()\n",
    "\n",
    "# Fashion-MNISTのデータ形状\n",
    "print(train_data.shape)         # 学習用データ\n",
    "print(train_label.shape)        # 学習用データのラベル\n",
    "print(test_data.shape)          # 検証用データ\n",
    "print(test_label.shape)         # 検証用データのラベル\n",
    "\n",
    "\n",
    "# データの形状を確認------------------------------\n",
    "import numpy as np\n",
    "# データ抽出\n",
    "train_data0 = train_data[0:10000, : , : ]\n",
    "train_label0 = train_label[0:10000]\n",
    "valid_data0 = train_data[10000:11000, : , : ]\n",
    "valid_label0 = train_label[10000:11000]\n",
    "\n",
    "# データ型\n",
    "print(train_data0.dtype, valid_data0.dtype)\n",
    "print(train_data0.shape, valid_data0.shape)\n",
    "\n",
    "# uint8 -> float32（<-この下の「channelの追加」取りやめに伴う変更＠20221021）\n",
    "# train_data01 = train_data0.astype(\"float32\") / 255\n",
    "train_data1 = train_data0.astype(\"float32\") / 255\n",
    "# valid_data01 = valid_data0.astype(\"float32\") / 255\n",
    "valid_data1 = valid_data0.astype(\"float32\") / 255\n",
    "\n",
    "# channelの追加（<-この「channelの追加」と取りやめる＠20221021）\n",
    "# train_data1 = train_data01.reshape(train_data01.shape[0], train_data01.shape[1], train_data01.shape[2], 1)\n",
    "# valid_data1 = valid_data01.reshape(valid_data01.shape[0], valid_data01.shape[1], valid_data01.shape[2], 1)\n",
    "\n",
    "# データ型\n",
    "print(train_data1.dtype, valid_data1.dtype)\n",
    "print(train_data1.shape, valid_data1.shape)\n",
    "\n",
    "print(\"学習用データ\")\n",
    "print(train_data1.min(), \"-\", train_data1.max())\n",
    "print(train_label0.min(), \"-\", train_label0.max())\n",
    "print(\"検証用データ\")\n",
    "print(valid_data1.min(), \"-\", valid_data1.max())\n",
    "print(valid_label0.min(), \"-\", valid_label0.max())\n",
    "\n",
    "\n",
    "# one-hotベクトルに変換----------------------\n",
    "# keras.utilsからto_categoricalをインポート\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ラベルの表示\n",
    "print(\"学習用\", train_label0, len(train_label0))\n",
    "print(\"検証用\", valid_label0, len(valid_label0))\n",
    "\n",
    "# one-hot vector\n",
    "train_label1 = to_categorical(train_label0)\n",
    "valid_label1 = to_categorical(valid_label0)\n",
    "\n",
    "print(\"学習用\", train_label1, len(train_label1))\n",
    "print(\"検証用\", valid_label1, len(valid_label1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K--JjXOp27UU"
   },
   "source": [
    "## 畳み込み層\n",
    "畳み込み層を1つだけ追加します。入力層の後に畳み込み層を1層、挿入します。その後、Flattenを経て全結合層、そして出力層に接続するという構成になります。先ほど作った全結合層（とドロップアウト）はそのままです。まず、Conv2D()メソッドで、3×3の2次元フィルタを設定します。主な引数に以下があります。\n",
    "- filters：フィルタの数\n",
    "- kernel_size：フィルタのサイズ\n",
    "- padding：padding = \"same\"でゼロパディング\n",
    "- input_shape：入力データの形状（行数, 列数, チャネル）\n",
    "\n",
    "Flatten()は畳み込み層の出力を全結合層に入力するための処理を行います。畳み込み層の出力には特徴マップ（2次元画像）とチャネル（フィルタ）が含まれますが、全結合層には1次元配列で入力します。\n",
    "\n",
    "ネットワークの構成は以下のようになります。\n",
    "- 畳み込み層（フィルタ数：32）\n",
    "- 全結合層\n",
    "- ドロップアウト\n",
    "- 全結合層\n",
    "- ドロップアウト\n",
    "- 出力層（ユニット数：10）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ktseEHgaYnv",
    "outputId": "7ae92273-e3c0-427d-b587-df47abc38c68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuni/Documents/computer-vision-practices/venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1750167869.600949   19261 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10249 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:04:00.0, compute capability: 8.6\n",
      "I0000 00:00:1750167869.601934   19261 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 1661 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m6,422,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,457,290</span> (24.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,457,290\u001b[0m (24.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,457,290</span> (24.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,457,290\u001b[0m (24.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28) (10000, 10)\n",
      "(1000, 28, 28) (1000, 10)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750167870.794892   21004 service.cc:152] XLA service 0x78dde4005da0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1750167870.794908   21004 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "I0000 00:00:1750167870.794911   21004 service.cc:160]   StreamExecutor device (1): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-06-17 22:44:30.821553: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1750167870.911740   21004 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
      "2025-06-17 22:44:32.322230: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_989', 708 bytes spill stores, 584 bytes spill loads\n",
      "\n",
      "2025-06-17 22:44:32.378326: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_989', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-06-17 22:44:32.479962: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1005', 592 bytes spill stores, 500 bytes spill loads\n",
      "\n",
      "2025-06-17 22:44:32.550572: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_989', 596 bytes spill stores, 512 bytes spill loads\n",
      "\n",
      "2025-06-17 22:44:32.675245: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_989', 452 bytes spill stores, 452 bytes spill loads\n",
      "\n",
      "2025-06-17 22:44:32.944866: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_989', 592 bytes spill stores, 500 bytes spill loads\n",
      "\n",
      "2025-06-17 22:44:33.508947: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1005', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-06-17 22:44:33.600537: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1005', 452 bytes spill stores, 452 bytes spill loads\n",
      "\n",
      "2025-06-17 22:44:33.604364: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_989', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-06-17 22:44:33.674334: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1005', 708 bytes spill stores, 584 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 80/157\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3270 - loss: 1.8308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750167875.261149   21004 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4177 - loss: 1.5791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 22:44:38.693859: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_80', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-06-17 22:44:38.889859: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-06-17 22:44:38.949684: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "2025-06-17 22:44:40.080928: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.4186 - loss: 1.5767 - val_accuracy: 0.7070 - val_loss: 0.7375\n",
      "Epoch 2/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6965 - loss: 0.7796 - val_accuracy: 0.8080 - val_loss: 0.5232\n",
      "Epoch 3/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7618 - loss: 0.6396 - val_accuracy: 0.7560 - val_loss: 0.6441\n",
      "Epoch 4/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7848 - loss: 0.5783 - val_accuracy: 0.7380 - val_loss: 0.6802\n",
      "Epoch 5/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8109 - loss: 0.5303 - val_accuracy: 0.7910 - val_loss: 0.5421\n",
      "Epoch 6/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.4831 - val_accuracy: 0.8380 - val_loss: 0.4131\n",
      "Epoch 7/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8418 - loss: 0.4473 - val_accuracy: 0.8770 - val_loss: 0.3740\n",
      "Epoch 8/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.4162 - val_accuracy: 0.8860 - val_loss: 0.3272\n",
      "Epoch 9/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.4007 - val_accuracy: 0.8550 - val_loss: 0.3847\n",
      "Epoch 10/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.3793 - val_accuracy: 0.8870 - val_loss: 0.3223\n",
      "Epoch 11/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.3534 - val_accuracy: 0.8960 - val_loss: 0.3294\n",
      "Epoch 12/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8733 - loss: 0.3460 - val_accuracy: 0.8850 - val_loss: 0.3246\n",
      "Epoch 13/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8855 - loss: 0.3230 - val_accuracy: 0.8960 - val_loss: 0.3232\n",
      "Epoch 14/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.3064 - val_accuracy: 0.8860 - val_loss: 0.3230\n",
      "Epoch 15/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8887 - loss: 0.2990 - val_accuracy: 0.8680 - val_loss: 0.3799\n",
      "Epoch 16/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.2900 - val_accuracy: 0.8900 - val_loss: 0.3119\n",
      "Epoch 17/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2766 - val_accuracy: 0.8850 - val_loss: 0.3384\n",
      "Epoch 18/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.2631 - val_accuracy: 0.8970 - val_loss: 0.3386\n",
      "Epoch 19/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.2544 - val_accuracy: 0.8900 - val_loss: 0.3324\n",
      "Epoch 20/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2468 - val_accuracy: 0.8900 - val_loss: 0.3296\n",
      "Epoch 21/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2433 - val_accuracy: 0.9040 - val_loss: 0.3289\n",
      "Epoch 22/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2367 - val_accuracy: 0.8970 - val_loss: 0.3247\n",
      "Epoch 23/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9216 - loss: 0.2154 - val_accuracy: 0.8920 - val_loss: 0.3266\n",
      "Epoch 24/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2094 - val_accuracy: 0.8560 - val_loss: 0.4210\n",
      "Epoch 25/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2150 - val_accuracy: 0.8980 - val_loss: 0.3258\n",
      "Epoch 26/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2054 - val_accuracy: 0.8980 - val_loss: 0.3309\n",
      "Epoch 27/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9279 - loss: 0.2024 - val_accuracy: 0.8860 - val_loss: 0.3801\n",
      "Epoch 28/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.1885 - val_accuracy: 0.8800 - val_loss: 0.3833\n",
      "Epoch 29/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.1964 - val_accuracy: 0.9070 - val_loss: 0.3293\n",
      "Epoch 30/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9330 - loss: 0.1774 - val_accuracy: 0.8920 - val_loss: 0.3743\n",
      "uint8\n",
      "(2000, 28, 28)\n",
      "float32\n",
      "(2000, 28, 28)\n",
      "評価用データ\n",
      "0.0 - 1.0\n",
      "0 - 9\n",
      "検証用 [9 2 1 ... 3 6 0] 2000\n",
      "検証用 [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]] 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 22:44:53.498405: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_80', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8775 - loss: 0.4488\n",
      "Test Loss :  0.4614989161491394\n",
      "Test Accuracy :  0.8700000047683716\n"
     ]
    }
   ],
   "source": [
    "#（実行には7分くらいかかります）\n",
    "# ニューラルネットワークの構成----------------------------\n",
    "# Neural Network\n",
    "img_row = 28                # 入力層のユニット数\n",
    "img_col = 28\n",
    "unit_middle1 = 256          # 中間層のユニット数\n",
    "unit_middle2 = 128\n",
    "unit_output = 10            # 出力層のユニット数\n",
    "learning_rate = 0.1         # 学習係数\n",
    "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
    "batch_size = 64             # ミニバッチのサイズ\n",
    "\n",
    "\n",
    "# ニューラルネットワークの構築-----------------------------\n",
    "# keras.modelsからSequentialをインポート\n",
    "from tensorflow.keras.models import Sequential\n",
    "# keras.layersからDenseとFlattenをインポート\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout     # Dropoutを追加\n",
    "from tensorflow.keras.layers import Conv2D        # Conv2Dを追加\n",
    "# keras.optimizersからSGDをインポート\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 畳み込み層\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters = 32,                   # フィルタの数\n",
    "        kernel_size = (3, 3),           # フィルタのサイズ\n",
    "        padding = \"same\",               # ゼロパディング\n",
    "        input_shape = (img_row, img_col, 1),      # 入力データの形状\n",
    "        activation = \"relu\"             # 活性化関数\n",
    "    ))\n",
    "\n",
    "# (28, 28, 32) -> (25088)\n",
    "model.add(Flatten())\n",
    "\n",
    "# 中間層\n",
    "model.add(Dense(unit_middle1, activation = \"relu\"))    # 中間層1\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "model.add(Dense(unit_middle2, activation = \"relu\"))    # 中間層2\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(unit_output, activation = \"softmax\"))\n",
    "\n",
    "# モデルの概要を出力\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# モデルのコンパイル---------------------------------\n",
    "model.compile(\n",
    "    optimizer = SGD(learning_rate),            # SGD\n",
    "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
    "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
    ")\n",
    "\n",
    "\n",
    "# 学習を実行し、結果を出力する\n",
    "print(train_data1.shape, train_label1.shape)\n",
    "print(valid_data1.shape, valid_label1.shape)\n",
    "history = model.fit(train_data1,\n",
    "                    train_label1,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (valid_data1, valid_label1)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 検証-----------------------------------------------\n",
    "# データ抽出\n",
    "test_data0 = test_data[0:2000, : , : ]\n",
    "test_label0 = test_label[0:2000]\n",
    "\n",
    "# データ型\n",
    "print(test_data0.dtype)\n",
    "print(test_data0.shape)\n",
    "\n",
    "# uint8 -> float32\n",
    "test_data1 = test_data0.astype(\"float32\") / 255\n",
    "\n",
    "# データ型\n",
    "print(test_data1.dtype)\n",
    "print(test_data1.shape)\n",
    "\n",
    "print(\"評価用データ\")\n",
    "print(test_data1.min(), \"-\", test_data1.max())\n",
    "print(test_label0.min(), \"-\", test_label0.max())\n",
    "\n",
    "\n",
    "# ラベルの表示\n",
    "print(\"検証用\", test_label0, len(test_label0))\n",
    "\n",
    "# one-hot vector\n",
    "test_label1 = to_categorical(test_label0)\n",
    "print(\"検証用\", test_label1, len(test_label1))\n",
    "\n",
    "\n",
    "# 検証\n",
    "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
    "# 検証用データの誤り率\n",
    "print(\"Test Loss : \", score[0])\n",
    "# 検証用データの正確度\n",
    "print(\"Test Accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_OGkWhSndi8"
   },
   "source": [
    "損失関数の値、正確度を図示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "XUNnM5UVnq2t",
    "outputId": "9e5bf63e-32ef-41c3-9cc8-d076f5608dec"
   },
   "outputs": [],
   "source": [
    "# Loss & Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 学習用データの損失\n",
    "plt.plot(history.history[\"loss\"],\n",
    "         color = \"blue\",\n",
    "         label = \"train_loss\")\n",
    "# 検証用データの損失\n",
    "plt.plot(history.history[\"val_loss\"],\n",
    "         color = \"red\",\n",
    "         label = \"val_loss\")\n",
    "plt.legend(loc = \"upper right\")       # 凡例\n",
    "plt.grid()                            # グリッド\n",
    "plt.xlabel(\"epoch\")                   # x軸\n",
    "plt.ylabel(\"loss\")                    # y軸\n",
    "plt.show()\n",
    "\n",
    "# 学習用データの正確度\n",
    "plt.plot(history.history[\"accuracy\"],\n",
    "         color = \"blue\",\n",
    "         label = \"train_acc\")\n",
    "# 検証用データの損失\n",
    "plt.plot(history.history[\"val_accuracy\"],\n",
    "         color = \"red\",\n",
    "         label = \"val_acc\")\n",
    "plt.legend(loc = \"lower right\")       # 凡例\n",
    "plt.grid()                            # グリッド\n",
    "plt.xlabel(\"epoch\")                   # x軸\n",
    "plt.ylabel(\"accuracy\")                # y軸\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vopssX2aZVKg"
   },
   "source": [
    "## プーリング層\n",
    "プーリング層を追加します。畳み込み層の後にプーリング層を1つ挿入します。その後、Flattenを経て全結合層に接続し、出力層に接続するという構成になります。MaxPooling2D()メソッドで、2×2の領域で最大値を取り出します（最大値プーリング）。主な引数に以下があります。\n",
    "- pool_size：プーリングのサイズ（最大値を取る範囲）\n",
    "- strides：defaultは\"None\"で、pool_size（2×2なら、縦と横に2つずつずらす）\n",
    "\n",
    "ネットワークの構成は以下のようになります。\n",
    "- 畳み込み層（フィルタ数：32）\n",
    "- プーリング層（最大値）\n",
    "- 全結合層\n",
    "- ドロップアウト\n",
    "- 全結合層\n",
    "- ドロップアウト\n",
    "- 出力層（ユニット数：10）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fjrqbq_PmGsa",
    "outputId": "9b44e0be-2f26-4bfb-c382-6bd3e00a834e"
   },
   "outputs": [],
   "source": [
    "#（実行には4分くらいかかります）\n",
    "# ニューラルネットワークの構成----------------------------\n",
    "# Neural Network\n",
    "img_row = 28                # 入力層のユニット数\n",
    "img_col = 28\n",
    "unit_middle1 = 256          # 中間層のユニット数\n",
    "unit_middle2 = 128\n",
    "unit_output = 10            # 出力層のユニット数\n",
    "learning_rate = 0.1         # 学習係数\n",
    "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
    "batch_size = 64             # ミニバッチのサイズ\n",
    "\n",
    "\n",
    "# ニューラルネットワークの構築-----------------------------\n",
    "# keras.modelsからSequentialをインポート\n",
    "from tensorflow.keras.models import Sequential\n",
    "# keras.layersからDenseとFlattenをインポート\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout     # Dropoutを追加\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D        # MaxPooling2Dを追加\n",
    "# keras.optimizersからSGDをインポート\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 畳み込み層\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters = 32,                   # フィルタの数\n",
    "        kernel_size = (3, 3),           # フィルタのサイズ\n",
    "        padding = \"same\",               # ゼロパディング\n",
    "        input_shape = (img_row, img_col, 1),      # 入力データの形状\n",
    "        activation = \"relu\"             # 活性化関数\n",
    "    ))\n",
    "\n",
    "# プーリング層(14, 14, 32)\n",
    "model.add(\n",
    "    MaxPooling2D(pool_size = (2, 2)))   # プーリングサイズ\n",
    "\n",
    "# (28, 28, 32) -> (25088)\n",
    "model.add(Flatten())\n",
    "\n",
    "# 中間層\n",
    "model.add(Dense(unit_middle1, activation = \"relu\"))    # 中間層1\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "model.add(Dense(unit_middle2, activation = \"relu\"))    # 中間層2\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(unit_output, activation = \"softmax\"))\n",
    "\n",
    "# モデルの概要を出力\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# モデルのコンパイル---------------------------------\n",
    "model.compile(\n",
    "    optimizer = SGD(learning_rate),            # SGD\n",
    "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
    "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
    ")\n",
    "\n",
    "\n",
    "# 学習を実行し、結果を出力する\n",
    "print(train_data1.shape, train_label1.shape)\n",
    "print(valid_data1.shape, valid_label1.shape)\n",
    "history = model.fit(train_data1,\n",
    "                    train_label1,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (valid_data1, valid_label1)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 検証-----------------------------------------------\n",
    "# データ抽出\n",
    "test_data0 = test_data[0:2000, : , : ]\n",
    "test_label0 = test_label[0:2000]\n",
    "\n",
    "# データ型\n",
    "print(test_data0.dtype)\n",
    "print(test_data0.shape)\n",
    "\n",
    "# uint8 -> float32\n",
    "test_data1 = test_data0.astype(\"float32\") / 255\n",
    "\n",
    "# データ型\n",
    "print(test_data1.dtype)\n",
    "print(test_data1.shape)\n",
    "\n",
    "print(\"評価用データ\")\n",
    "print(test_data1.min(), \"-\", test_data1.max())\n",
    "print(test_label0.min(), \"-\", test_label0.max())\n",
    "\n",
    "\n",
    "# ラベルの表示\n",
    "print(\"検証用\", test_label0, len(test_label0))\n",
    "\n",
    "# one-hot vector\n",
    "test_label1 = to_categorical(test_label0)\n",
    "print(\"検証用\", test_label1, len(test_label1))\n",
    "\n",
    "\n",
    "# 検証\n",
    "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
    "# 検証用データの誤り率\n",
    "print(\"Test Loss : \", score[0])\n",
    "# 検証用データの正確度\n",
    "print(\"Test Accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UZIrI5Kzpr-"
   },
   "source": [
    "損失関数の値、正確度を図示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "i0n90ettztTl",
    "outputId": "d23c70dc-af89-413a-bd94-1169fac74922"
   },
   "outputs": [],
   "source": [
    "# Loss & Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 学習用データの損失\n",
    "plt.plot(history.history[\"loss\"],\n",
    "         color = \"blue\",\n",
    "         label = \"train_loss\")\n",
    "# 検証用データの損失\n",
    "plt.plot(history.history[\"val_loss\"],\n",
    "         color = \"red\",\n",
    "         label = \"val_loss\")\n",
    "plt.legend(loc = \"upper right\")       # 凡例\n",
    "plt.grid()                            # グリッド\n",
    "plt.xlabel(\"epoch\")                   # x軸\n",
    "plt.ylabel(\"loss\")                    # y軸\n",
    "plt.show()\n",
    "\n",
    "# 学習用データの正確度\n",
    "plt.plot(history.history[\"accuracy\"],\n",
    "         color = \"blue\",\n",
    "         label = \"train_acc\")\n",
    "# 検証用データの損失\n",
    "plt.plot(history.history[\"val_accuracy\"],\n",
    "         color = \"red\",\n",
    "         label = \"val_acc\")\n",
    "plt.legend(loc = \"lower right\")       # 凡例\n",
    "plt.grid()                            # グリッド\n",
    "plt.xlabel(\"epoch\")                   # x軸\n",
    "plt.ylabel(\"accuracy\")                # y軸\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbVRh994qv8c"
   },
   "source": [
    "## 畳み込み層とプーリング層をもう1セット追加\n",
    "畳み込み層とプーリング層をもう1セット追加してみましょう。ネットワークの構成は以下のようになります。\n",
    "- 畳み込み層（フィルタ数：32）\n",
    "- プーリング層（最大値）\n",
    "- 畳み込み層（フィルタ数：64）\n",
    "- プーリング層（最大値）\n",
    "- Flatten\n",
    "- 全結合層\n",
    "- ドロップアウト\n",
    "- 全結合層\n",
    "- ドロップアウト\n",
    "- 出力層（ユニット数：10）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRtfDPcNrCNb",
    "outputId": "ae2a5af0-0630-4f2c-b8d0-e272aa480c52"
   },
   "outputs": [],
   "source": [
    "#（実行には7分くらいかかります）\n",
    "# ニューラルネットワークの構成----------------------------\n",
    "# Neural Network\n",
    "img_row = 28                # 入力層のユニット数\n",
    "img_col = 28\n",
    "unit_middle1 = 256          # 中間層のユニット数\n",
    "unit_middle2 = 128\n",
    "unit_output = 10            # 出力層のユニット数\n",
    "learning_rate = 0.1         # 学習係数\n",
    "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
    "batch_size = 64             # ミニバッチのサイズ\n",
    "\n",
    "\n",
    "# ニューラルネットワークの構築-----------------------------\n",
    "# keras.modelsからSequentialをインポート\n",
    "from tensorflow.keras.models import Sequential\n",
    "# keras.layersからDenseとFlattenをインポート\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout     # Dropoutを追加\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D        # MaxPooling2Dを追加\n",
    "# keras.optimizersからSGDをインポート\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 畳み込み層1\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters = 32,                   # フィルタの数\n",
    "        kernel_size = (3, 3),           # フィルタのサイズ\n",
    "        padding = \"same\",               # ゼロパディング\n",
    "        input_shape = (img_row, img_col, 1),      # 入力データの形状\n",
    "        activation = \"relu\"             # 活性化関数\n",
    "    ))\n",
    "\n",
    "# プーリング層1(14, 14, 32)\n",
    "model.add(\n",
    "    MaxPooling2D(pool_size = (2, 2)))   # プーリングサイズ\n",
    "\n",
    "# 畳み込み層2\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters = 64,                   # フィルタの数\n",
    "        kernel_size = (3, 3),           # フィルタのサイズ\n",
    "        padding = \"same\",               # ゼロパディング\n",
    "        activation = \"relu\"             # 活性化関数\n",
    "    ))\n",
    "\n",
    "# プーリング層2(7, 7, 64)\n",
    "model.add(\n",
    "    MaxPooling2D(pool_size = (2, 2)))   # プーリングサイズ\n",
    "\n",
    "\n",
    "# (7, 7, 64) -> (3136)\n",
    "model.add(Flatten())\n",
    "\n",
    "# 中間層\n",
    "model.add(Dense(unit_middle1, activation = \"relu\"))    # 中間層1\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "model.add(Dense(unit_middle2, activation = \"relu\"))    # 中間層2\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(unit_output, activation = \"softmax\"))\n",
    "\n",
    "# モデルの概要を出力\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# モデルのコンパイル---------------------------------\n",
    "model.compile(\n",
    "    optimizer = SGD(learning_rate),            # SGD\n",
    "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
    "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
    ")\n",
    "\n",
    "\n",
    "# 学習を実行し、結果を出力する\n",
    "print(train_data1.shape, train_label1.shape)\n",
    "print(valid_data1.shape, valid_label1.shape)\n",
    "history = model.fit(train_data1,\n",
    "                    train_label1,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (valid_data1, valid_label1)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 検証-----------------------------------------------\n",
    "# データ抽出\n",
    "test_data0 = test_data[0:2000, : , : ]\n",
    "test_label0 = test_label[0:2000]\n",
    "\n",
    "# データ型\n",
    "print(test_data0.dtype)\n",
    "print(test_data0.shape)\n",
    "\n",
    "# uint8 -> float32\n",
    "test_data1 = test_data0.astype(\"float32\") / 255\n",
    "\n",
    "# データ型\n",
    "print(test_data1.dtype)\n",
    "print(test_data1.shape)\n",
    "\n",
    "print(\"評価用データ\")\n",
    "print(test_data1.min(), \"-\", test_data1.max())\n",
    "print(test_label0.min(), \"-\", test_label0.max())\n",
    "\n",
    "\n",
    "# ラベルの表示\n",
    "print(\"検証用\", test_label0, len(test_label0))\n",
    "\n",
    "# one-hot vector\n",
    "test_label1 = to_categorical(test_label0)\n",
    "print(\"検証用\", test_label1, len(test_label1))\n",
    "\n",
    "\n",
    "# 検証\n",
    "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
    "# 検証用データの誤り率\n",
    "print(\"Test Loss : \", score[0])\n",
    "# 検証用データの正確度\n",
    "print(\"Test Accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgTIkQEBtRHt"
   },
   "source": [
    "損失関数の値、正確度を図示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "T54ihNvotYuE",
    "outputId": "7e90695e-e523-418b-cde4-60cfa52ec747"
   },
   "outputs": [],
   "source": [
    "# Loss & Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 学習用データの損失\n",
    "plt.plot(history.history[\"loss\"],\n",
    "         color = \"blue\",\n",
    "         label = \"train_loss\")\n",
    "# 検証用データの損失\n",
    "plt.plot(history.history[\"val_loss\"],\n",
    "         color = \"red\",\n",
    "         label = \"val_loss\")\n",
    "plt.legend(loc = \"upper right\")       # 凡例\n",
    "plt.grid()                            # グリッド\n",
    "plt.xlabel(\"epoch\")                   # x軸\n",
    "plt.ylabel(\"loss\")                    # y軸\n",
    "plt.show()\n",
    "\n",
    "# 学習用データの正確度\n",
    "plt.plot(history.history[\"accuracy\"],\n",
    "         color = \"blue\",\n",
    "         label = \"train_acc\")\n",
    "# 検証用データの損失\n",
    "plt.plot(history.history[\"val_accuracy\"],\n",
    "         color = \"red\",\n",
    "         label = \"val_acc\")\n",
    "plt.legend(loc = \"lower right\")       # 凡例\n",
    "plt.grid()                            # グリッド\n",
    "plt.xlabel(\"epoch\")                   # x軸\n",
    "plt.ylabel(\"accuracy\")                # y軸\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
