{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEQF3J2fb6RN"
      },
      "source": [
        "第13回の演習です。前回、Kerasで構築したニューラルネットワークに対して、ハイパーパラメータを調整します。\n",
        "左上の「ファイル」＞「ドライブにコピーを保存」を選択して、Google DriveにNotebookを保存します。ご自身のGoogleドライブの\"Colab Notebooks\"フォルダで、保存したNotebookを右クリックし、「アプリで開く」＞「Google Colaboratory」を選択します。その上で、各コードを実行するには、以下のコマンドを実行してください。実行は「再生」ボタンを押します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arnzzHVKbsJ_",
        "outputId": "933fb88d-3f88-4a3e-ba09-b4230685fd87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chapter 13\n"
          ]
        }
      ],
      "source": [
        "print(\"Chapter 13\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TumMt-4e4YFi"
      },
      "source": [
        "# ニューラルネットワークのハイパーパラメータの調整\n",
        "前回、Kerasでニューラルネットワークを構築し、Fashion-MNISTデータセットのアイテム画像を認識しました。ところが、その正確度（識別率）は80%弱で、scikit-learnライブラリのニューラルネットワークよりも悪化しています。これは未だ、ハイパーパラメータの調整をやっていないからです。そこで、ハイパーパラメータを調整していきます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRssDCF7zLsI"
      },
      "source": [
        "## GPUの利用\n",
        "時間がかかるので、GPUを使います。Coogle Colaboratoryのメニュー「ランライム」をクリックし、「ランタイムのタイプを変更」を選択します。「ハードウェアアクセラレータ」を\"GPU\"に変更します。これで計算処理が多少速く終了するようになるでしょう。ただ、「Colabでの使用量上限に達したため、現在GPUに接続できません」というメッセージが出ると、GPUが割り当てられないこともあります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzWfed7WaY-z"
      },
      "source": [
        "## データセットの用意と前処理\n",
        "まずはデータセットを用意し、前処理を済ませます。これらはこの回では共通の操作ですので、一度実行しておけばよいでしょう。ただし、「ランタイムリセット」されてしまったら再実行します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spOFM6SdBVVE",
        "outputId": "70788378-2b5a-4bac-84c2-cfe961c373cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "uint8 uint8\n",
            "(10000, 28, 28) (1000, 28, 28)\n",
            "float32 float32\n",
            "(10000, 28, 28) (1000, 28, 28)\n",
            "学習用データ\n",
            "0.0 - 1.0\n",
            "0 - 9\n",
            "検証用データ\n",
            "0.0 - 1.0\n",
            "0 - 9\n",
            "学習用 [9 0 0 ... 0 6 6] 10000\n",
            "検証用 [8 7 6 8 7 7 2 0 5 3 5 5 1 3 9 4 1 9 3 2 8 2 9 3 4 5 1 0 3 2 8 5 3 8 2 2 9\n",
            " 7 7 9 9 1 2 6 7 6 6 6 6 7 3 7 8 5 9 5 9 1 5 9 8 3 6 1 1 0 3 3 1 2 9 8 9 5\n",
            " 1 0 6 2 3 0 0 8 8 5 7 3 6 9 7 3 6 4 8 5 0 8 3 6 7 1 5 1 7 6 4 1 6 9 8 1 1\n",
            " 7 7 0 7 4 9 4 2 9 9 9 6 5 2 3 5 6 5 1 9 6 1 5 6 9 3 5 3 5 3 2 7 0 9 1 1 2\n",
            " 1 3 6 4 8 4 1 3 2 6 2 0 9 5 8 6 5 5 6 8 0 8 3 9 6 9 8 3 2 5 8 3 9 0 9 9 8\n",
            " 1 3 8 4 9 9 0 3 0 0 6 7 8 6 6 4 6 3 9 0 4 6 7 2 5 6 2 9 7 0 2 2 3 8 4 7 6\n",
            " 8 7 3 6 2 1 3 7 0 4 7 7 5 9 4 9 4 7 1 5 4 6 2 7 1 6 1 4 5 5 8 2 9 9 9 4 7\n",
            " 7 5 2 0 9 1 5 0 4 9 6 8 8 3 3 6 2 6 4 5 8 0 5 2 3 4 9 2 8 5 7 4 4 0 5 3 5\n",
            " 3 5 3 0 0 4 5 0 1 7 6 7 9 0 8 1 4 9 0 6 9 8 8 9 2 9 3 4 2 2 5 9 9 4 1 9 4\n",
            " 4 5 1 9 2 6 1 2 5 7 3 9 9 2 2 7 1 5 0 9 6 6 4 5 4 4 1 1 6 8 0 7 9 2 3 0 8\n",
            " 7 3 2 2 5 3 5 5 0 8 1 4 5 1 8 6 1 1 0 1 5 1 9 5 9 1 0 4 9 5 9 2 6 3 7 7 3\n",
            " 7 2 8 1 5 0 2 8 3 6 6 1 0 8 1 3 5 5 1 4 8 9 3 0 3 3 5 6 4 6 1 3 0 0 7 5 2\n",
            " 9 2 8 0 4 2 2 0 7 9 7 7 6 4 0 3 3 6 2 0 4 5 8 1 3 5 9 6 6 0 6 5 8 8 4 7 6\n",
            " 2 7 3 4 1 5 8 5 5 2 8 3 3 0 7 8 4 1 4 3 1 3 8 1 9 3 4 9 8 0 6 1 1 4 4 5 3\n",
            " 2 4 0 7 9 2 4 9 9 9 0 7 1 3 7 4 3 4 3 1 3 5 1 9 1 7 3 3 8 3 8 4 9 1 0 1 2\n",
            " 5 3 9 7 4 6 0 0 2 2 3 1 3 0 1 2 9 7 1 0 5 1 9 1 3 5 8 7 4 8 4 5 6 3 7 5 7\n",
            " 3 8 1 4 7 5 2 0 4 2 8 7 7 4 9 2 3 6 9 6 7 3 5 2 9 9 2 6 0 6 6 4 7 3 5 7 2\n",
            " 0 0 6 9 6 1 3 0 4 2 1 3 4 9 5 9 4 8 0 5 8 8 0 4 6 2 0 4 7 8 8 4 7 7 4 5 5\n",
            " 4 1 7 9 4 1 8 5 3 3 0 5 7 9 7 1 0 2 6 5 2 5 9 9 2 1 9 5 6 8 2 5 5 0 3 6 4\n",
            " 0 1 6 2 5 5 7 7 6 8 2 6 7 1 7 9 2 9 3 8 8 8 0 9 0 6 3 1 1 9 6 9 2 9 5 9 9\n",
            " 9 2 8 3 6 8 6 5 8 9 5 6 3 7 8 7 5 8 7 6 3 7 2 9 8 0 2 1 0 6 1 6 5 6 4 2 8\n",
            " 1 9 2 9 5 6 4 8 2 3 9 4 3 3 9 0 1 5 6 4 6 5 3 3 6 7 9 7 1 3 7 8 4 8 4 3 6\n",
            " 6 4 4 3 2 4 4 9 7 5 9 9 3 0 2 6 7 6 8 0 2 2 9 6 0 1 9 3 3 9 0 9 1 4 5 4 4\n",
            " 9 7 8 7 5 0 4 4 8 8 5 7 4 8 9 3 9 4 6 7 8 9 0 5 6 2 2 3 5 4 4 3 7 8 2 5 6\n",
            " 6 1 8 7 2 4 2 8 4 0 2 2 7 4 0 9 9 1 3 5 4 7 3 8 5 3 6 9 6 1 9 7 0 4 0 8 2\n",
            " 7 6 6 0 4 8 6 2 5 8 4 7 0 8 2 3 8 8 3 6 4 2 5 0 0 5 1 9 8 5 8 8 7 3 5 9 8\n",
            " 2 1 9 2 3 4 8 3 6 8 0 7 3 6 6 7 3 8 1 0 1 4 0 2 0 8 8 7 8 6 5 6 9 6 9 2 5\n",
            " 5] 1000\n",
            "学習用 [[0. 0. 0. ... 0. 0. 1.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]] 10000\n",
            "検証用 [[0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]] 1000\n"
          ]
        }
      ],
      "source": [
        "# Fashion-MNISTデータセット\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(train_data, train_label), (test_data, test_label) = fashion_mnist.load_data()\n",
        "\n",
        "# Fashion-MNISTのデータ形状\n",
        "print(train_data.shape)         # 学習用データ\n",
        "print(train_label.shape)        # 学習用データのラベル\n",
        "print(test_data.shape)          # 検証用データ\n",
        "print(test_label.shape)         # 検証用データのラベル\n",
        "\n",
        "\n",
        "# データの形状を確認------------------------------\n",
        "import numpy as np\n",
        "# データ抽出\n",
        "train_data0 = train_data[0:10000, : , : ]\n",
        "train_label0 = train_label[0:10000]\n",
        "valid_data0 = train_data[10000:11000, : , : ]\n",
        "valid_label0 = train_label[10000:11000]\n",
        "\n",
        "# データ型\n",
        "print(train_data0.dtype, valid_data0.dtype)\n",
        "print(train_data0.shape, valid_data0.shape)\n",
        "\n",
        "# uint8 -> float32\n",
        "train_data1 = train_data0.astype(\"float32\") / 255\n",
        "valid_data1 = valid_data0.astype(\"float32\") / 255\n",
        "\n",
        "# データ型\n",
        "print(train_data1.dtype, valid_data1.dtype)\n",
        "print(train_data1.shape, valid_data1.shape)\n",
        "\n",
        "print(\"学習用データ\")\n",
        "print(train_data1.min(), \"-\", train_data1.max())\n",
        "print(train_label0.min(), \"-\", train_label0.max())\n",
        "print(\"検証用データ\")\n",
        "print(valid_data1.min(), \"-\", valid_data1.max())\n",
        "print(valid_label0.min(), \"-\", valid_label0.max())\n",
        "\n",
        "\n",
        "# one-hotベクトルに変換----------------------\n",
        "# keras.utilsからto_categoricalをインポート\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ラベルの表示\n",
        "print(\"学習用\", train_label0, len(train_label0))\n",
        "print(\"検証用\", valid_label0, len(valid_label0))\n",
        "\n",
        "# one-hot vector\n",
        "train_label1 = to_categorical(train_label0)\n",
        "valid_label1 = to_categorical(valid_label0)\n",
        "\n",
        "print(\"学習用\", train_label1, len(train_label1))\n",
        "print(\"検証用\", valid_label1, len(valid_label1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8QGwZrvZeeT"
      },
      "source": [
        "## ネットワークの中間層を増やす\n",
        "前回のニューラルネットワークの構成に対して中間層を幾つか追加し、層を少しだけ深くすることから始めましょう。以下のプログラムコードは前回のものと同じですが、ネットワークの中間層を1層増やしています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rE_2-3XZ4Ix",
        "outputId": "842d0da9-8c33-48e5-ff08-2757fc30f890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(10000, 28, 28) (10000, 10)\n",
            "(1000, 28, 28) (1000, 10)\n",
            "Epoch 1/30\n",
            "157/157 [==============================] - 6s 5ms/step - loss: 1.9981 - accuracy: 0.3259 - val_loss: 1.6723 - val_accuracy: 0.3160\n",
            "Epoch 2/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 1.3260 - accuracy: 0.5776 - val_loss: 1.1297 - val_accuracy: 0.5480\n",
            "Epoch 3/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.0104 - accuracy: 0.6651 - val_loss: 0.9222 - val_accuracy: 0.6930\n",
            "Epoch 4/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.8508 - accuracy: 0.7078 - val_loss: 0.7778 - val_accuracy: 0.7200\n",
            "Epoch 5/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.7599 - accuracy: 0.7245 - val_loss: 0.7307 - val_accuracy: 0.7580\n",
            "Epoch 6/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.7039 - accuracy: 0.7397 - val_loss: 0.6552 - val_accuracy: 0.7720\n",
            "Epoch 7/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.6628 - accuracy: 0.7492 - val_loss: 0.6422 - val_accuracy: 0.7680\n",
            "Epoch 8/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.6336 - accuracy: 0.7608 - val_loss: 0.5935 - val_accuracy: 0.7780\n",
            "Epoch 9/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.6115 - accuracy: 0.7721 - val_loss: 0.6222 - val_accuracy: 0.7520\n",
            "Epoch 10/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.5878 - accuracy: 0.7820 - val_loss: 0.5560 - val_accuracy: 0.8030\n",
            "Epoch 11/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.5700 - accuracy: 0.7929 - val_loss: 0.5391 - val_accuracy: 0.8170\n",
            "Epoch 12/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.5528 - accuracy: 0.7989 - val_loss: 0.6052 - val_accuracy: 0.7510\n",
            "Epoch 13/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.5394 - accuracy: 0.8032 - val_loss: 0.5076 - val_accuracy: 0.8320\n",
            "Epoch 14/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.5251 - accuracy: 0.8111 - val_loss: 0.5288 - val_accuracy: 0.7880\n",
            "Epoch 15/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.5123 - accuracy: 0.8131 - val_loss: 0.4957 - val_accuracy: 0.8390\n",
            "Epoch 16/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.5005 - accuracy: 0.8218 - val_loss: 0.4687 - val_accuracy: 0.8490\n",
            "Epoch 17/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4941 - accuracy: 0.8200 - val_loss: 0.4555 - val_accuracy: 0.8520\n",
            "Epoch 18/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4825 - accuracy: 0.8265 - val_loss: 0.4664 - val_accuracy: 0.8470\n",
            "Epoch 19/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.4802 - accuracy: 0.8286 - val_loss: 0.4745 - val_accuracy: 0.8360\n",
            "Epoch 20/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.4712 - accuracy: 0.8315 - val_loss: 0.4576 - val_accuracy: 0.8450\n",
            "Epoch 21/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.4649 - accuracy: 0.8349 - val_loss: 0.4373 - val_accuracy: 0.8620\n",
            "Epoch 22/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4591 - accuracy: 0.8359 - val_loss: 0.4677 - val_accuracy: 0.8500\n",
            "Epoch 23/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4536 - accuracy: 0.8378 - val_loss: 0.4946 - val_accuracy: 0.8150\n",
            "Epoch 24/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.4466 - accuracy: 0.8413 - val_loss: 0.4508 - val_accuracy: 0.8390\n",
            "Epoch 25/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.4433 - accuracy: 0.8427 - val_loss: 0.5303 - val_accuracy: 0.8060\n",
            "Epoch 26/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.4357 - accuracy: 0.8446 - val_loss: 0.4348 - val_accuracy: 0.8530\n",
            "Epoch 27/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.4330 - accuracy: 0.8456 - val_loss: 0.4384 - val_accuracy: 0.8480\n",
            "Epoch 28/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4283 - accuracy: 0.8434 - val_loss: 0.4152 - val_accuracy: 0.8670\n",
            "Epoch 29/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.4233 - accuracy: 0.8482 - val_loss: 0.4519 - val_accuracy: 0.8440\n",
            "Epoch 30/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.4187 - accuracy: 0.8522 - val_loss: 0.5421 - val_accuracy: 0.8190\n",
            "uint8\n",
            "(2000, 28, 28)\n",
            "float32\n",
            "(2000, 28, 28)\n",
            "評価用データ\n",
            "0.0 - 1.0\n",
            "0 - 9\n",
            "検証用 [9 2 1 ... 3 6 0] 2000\n",
            "検証用 [[0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]] 2000\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.8125\n",
            "Test Loss :  0.5557945370674133\n",
            "Test Accuracy :  0.8125\n"
          ]
        }
      ],
      "source": [
        "# ニューラルネットワークの構成----------------------------\n",
        "# Neural Network\n",
        "img_row = 28                # 入力層のユニット数\n",
        "img_col = 28\n",
        "unit_middle1 = 256          # 中間層のユニット数\n",
        "unit_middle2 = 128\n",
        "unit_output = 10            # 出力層のユニット数\n",
        "learning_rate = 0.1         # 学習係数\n",
        "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
        "batch_size = 64             # ミニバッチのサイズ\n",
        "\n",
        "\n",
        "# ニューラルネットワークの構築-----------------------------\n",
        "# keras.modelsからSequentialをインポート\n",
        "from tensorflow.keras.models import Sequential\n",
        "# keras.layersからDenseとFlattenをインポート\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "# keras.optimizersからSGDをインポート\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 入力層\n",
        "model.add(Flatten(input_shape = (img_row, img_col)))\n",
        "\n",
        "# 中間層\n",
        "model.add(Dense(unit_middle1, activation = \"sigmoid\"))\n",
        "model.add(Dense(unit_middle2, activation = \"sigmoid\"))\n",
        "\n",
        "# 出力層\n",
        "model.add(Dense(unit_output, activation = \"softmax\"))\n",
        "\n",
        "# モデルの概要を出力\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# モデルのコンパイル---------------------------------\n",
        "model.compile(\n",
        "    optimizer = SGD(learning_rate),            # SGD\n",
        "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
        "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
        ")\n",
        "\n",
        "\n",
        "# 学習を実行し、結果を出力する\n",
        "print(train_data1.shape, train_label1.shape)\n",
        "print(valid_data1.shape, valid_label1.shape)\n",
        "history = model.fit(train_data1,\n",
        "                    train_label1,\n",
        "                    epochs = epochs,\n",
        "                    batch_size = batch_size,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (valid_data1, valid_label1)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# 検証-----------------------------------------------\n",
        "# データ抽出\n",
        "test_data0 = test_data[0:2000, : , : ]\n",
        "test_label0 = test_label[0:2000]\n",
        "\n",
        "# データ型\n",
        "print(test_data0.dtype)\n",
        "print(test_data0.shape)\n",
        "\n",
        "# uint8 -> float32\n",
        "test_data1 = test_data0.astype(\"float32\") / 255\n",
        "\n",
        "# データ型\n",
        "print(test_data1.dtype)\n",
        "print(test_data1.shape)\n",
        "\n",
        "print(\"評価用データ\")\n",
        "print(test_data1.min(), \"-\", test_data1.max())\n",
        "print(test_label0.min(), \"-\", test_label0.max())\n",
        "\n",
        "\n",
        "# ラベルの表示\n",
        "print(\"検証用\", test_label0, len(test_label0))\n",
        "\n",
        "# one-hot vector\n",
        "test_label1 = to_categorical(test_label0)\n",
        "print(\"検証用\", test_label1, len(test_label1))\n",
        "\n",
        "\n",
        "# 検証\n",
        "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
        "# 検証用データの誤り率\n",
        "print(\"Test Loss : \", score[0])\n",
        "# 検証用データの正確度\n",
        "print(\"Test Accuracy : \", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhaooPJscJaK"
      },
      "source": [
        "## ドロップアウト\n",
        "ドロップアウトは過学習を抑制する仕組みの一つで、ネットワークの層におけるユニットの一部がepochごとにランダムに削除されます。model.add()でドロップアウトを追加し、ユニットの削除割合を指定します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsQX0MsxcF0L",
        "outputId": "1d5b3327-b368-4331-e1c8-7a1b48e7a457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               200960    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(10000, 28, 28) (10000, 10)\n",
            "(1000, 28, 28) (1000, 10)\n",
            "Epoch 1/30\n",
            "157/157 [==============================] - 2s 6ms/step - loss: 2.2463 - accuracy: 0.1699 - val_loss: 1.8190 - val_accuracy: 0.4020\n",
            "Epoch 2/30\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 1.6969 - accuracy: 0.3393 - val_loss: 1.3781 - val_accuracy: 0.4390\n",
            "Epoch 3/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.4013 - accuracy: 0.4400 - val_loss: 1.1393 - val_accuracy: 0.6580\n",
            "Epoch 4/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.2464 - accuracy: 0.4995 - val_loss: 1.0325 - val_accuracy: 0.6320\n",
            "Epoch 5/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.1328 - accuracy: 0.5499 - val_loss: 0.9455 - val_accuracy: 0.6380\n",
            "Epoch 6/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.0697 - accuracy: 0.5799 - val_loss: 0.8758 - val_accuracy: 0.6550\n",
            "Epoch 7/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 1.0053 - accuracy: 0.6055 - val_loss: 0.8294 - val_accuracy: 0.6780\n",
            "Epoch 8/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.9551 - accuracy: 0.6250 - val_loss: 0.7824 - val_accuracy: 0.7190\n",
            "Epoch 9/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.9147 - accuracy: 0.6448 - val_loss: 0.7372 - val_accuracy: 0.7090\n",
            "Epoch 10/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.8834 - accuracy: 0.6538 - val_loss: 0.7086 - val_accuracy: 0.7420\n",
            "Epoch 11/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.8553 - accuracy: 0.6668 - val_loss: 0.6831 - val_accuracy: 0.7440\n",
            "Epoch 12/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.8275 - accuracy: 0.6848 - val_loss: 0.6643 - val_accuracy: 0.7410\n",
            "Epoch 13/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.8083 - accuracy: 0.6914 - val_loss: 0.6494 - val_accuracy: 0.7550\n",
            "Epoch 14/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.7822 - accuracy: 0.6972 - val_loss: 0.6293 - val_accuracy: 0.7640\n",
            "Epoch 15/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.7736 - accuracy: 0.7062 - val_loss: 0.6209 - val_accuracy: 0.7660\n",
            "Epoch 16/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.7665 - accuracy: 0.7096 - val_loss: 0.6097 - val_accuracy: 0.7710\n",
            "Epoch 17/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.7478 - accuracy: 0.7108 - val_loss: 0.6016 - val_accuracy: 0.7650\n",
            "Epoch 18/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.7369 - accuracy: 0.7162 - val_loss: 0.5917 - val_accuracy: 0.7560\n",
            "Epoch 19/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.7277 - accuracy: 0.7241 - val_loss: 0.5852 - val_accuracy: 0.7820\n",
            "Epoch 20/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.7255 - accuracy: 0.7211 - val_loss: 0.5835 - val_accuracy: 0.7750\n",
            "Epoch 21/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.7183 - accuracy: 0.7242 - val_loss: 0.5751 - val_accuracy: 0.7820\n",
            "Epoch 22/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.7078 - accuracy: 0.7293 - val_loss: 0.5888 - val_accuracy: 0.7800\n",
            "Epoch 23/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6995 - accuracy: 0.7325 - val_loss: 0.5720 - val_accuracy: 0.7860\n",
            "Epoch 24/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6948 - accuracy: 0.7362 - val_loss: 0.5656 - val_accuracy: 0.7930\n",
            "Epoch 25/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6884 - accuracy: 0.7397 - val_loss: 0.5584 - val_accuracy: 0.7830\n",
            "Epoch 26/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6752 - accuracy: 0.7464 - val_loss: 0.5548 - val_accuracy: 0.7860\n",
            "Epoch 27/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.6664 - accuracy: 0.7452 - val_loss: 0.5429 - val_accuracy: 0.8080\n",
            "Epoch 28/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6601 - accuracy: 0.7500 - val_loss: 0.5330 - val_accuracy: 0.8110\n",
            "Epoch 29/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.7502 - val_loss: 0.5340 - val_accuracy: 0.8090\n",
            "Epoch 30/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6510 - accuracy: 0.7574 - val_loss: 0.5318 - val_accuracy: 0.8040\n",
            "uint8\n",
            "(2000, 28, 28)\n",
            "float32\n",
            "(2000, 28, 28)\n",
            "評価用データ\n",
            "0.0 - 1.0\n",
            "0 - 9\n",
            "検証用 [9 2 1 ... 3 6 0] 2000\n",
            "検証用 [[0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]] 2000\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7740\n",
            "Test Loss :  0.5694349408149719\n",
            "Test Accuracy :  0.7739999890327454\n"
          ]
        }
      ],
      "source": [
        "# ニューラルネットワークの構成----------------------------\n",
        "# Neural Network\n",
        "img_row = 28                # 入力層のユニット数\n",
        "img_col = 28\n",
        "unit_middle1 = 256          # 中間層のユニット数\n",
        "unit_middle2 = 128\n",
        "unit_output = 10            # 出力層のユニット数\n",
        "learning_rate = 0.1         # 学習係数\n",
        "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
        "batch_size = 64             # ミニバッチのサイズ\n",
        "\n",
        "\n",
        "# ニューラルネットワークの構築-----------------------------\n",
        "# keras.modelsからSequentialをインポート\n",
        "from tensorflow.keras.models import Sequential\n",
        "# keras.layersからDenseとFlattenをインポート\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout     # Dropoutを追加\n",
        "# keras.optimizersからSGDをインポート\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 入力層\n",
        "model.add(Flatten(input_shape = (img_row, img_col)))\n",
        "\n",
        "# 中間層\n",
        "model.add(Dense(unit_middle1, activation = \"sigmoid\"))    # 中間層1\n",
        "model.add(Dropout(0.5))                                   # 中間層でドロップアウト\n",
        "model.add(Dense(unit_middle2, activation = \"sigmoid\"))    # 中間層2\n",
        "model.add(Dropout(0.5))                                   # 中間層でドロップアウト\n",
        "\n",
        "# 出力層\n",
        "model.add(Dense(unit_output, activation = \"softmax\"))\n",
        "\n",
        "# モデルの概要を出力\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# モデルのコンパイル---------------------------------\n",
        "model.compile(\n",
        "    optimizer = SGD(learning_rate),            # SGD\n",
        "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
        "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
        ")\n",
        "\n",
        "\n",
        "# 学習を実行し、結果を出力する\n",
        "print(train_data1.shape, train_label1.shape)\n",
        "print(valid_data1.shape, valid_label1.shape)\n",
        "history = model.fit(train_data1,\n",
        "                    train_label1,\n",
        "                    epochs = epochs,\n",
        "                    batch_size = batch_size,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (valid_data1, valid_label1)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# 検証-----------------------------------------------\n",
        "# データ抽出\n",
        "test_data0 = test_data[0:2000, : , : ]\n",
        "test_label0 = test_label[0:2000]\n",
        "\n",
        "# データ型\n",
        "print(test_data0.dtype)\n",
        "print(test_data0.shape)\n",
        "\n",
        "# uint8 -> float32\n",
        "test_data1 = test_data0.astype(\"float32\") / 255\n",
        "\n",
        "# データ型\n",
        "print(test_data1.dtype)\n",
        "print(test_data1.shape)\n",
        "\n",
        "print(\"評価用データ\")\n",
        "print(test_data1.min(), \"-\", test_data1.max())\n",
        "print(test_label0.min(), \"-\", test_label0.max())\n",
        "\n",
        "\n",
        "# ラベルの表示\n",
        "print(\"検証用\", test_label0, len(test_label0))\n",
        "\n",
        "# one-hot vector\n",
        "test_label1 = to_categorical(test_label0)\n",
        "print(\"検証用\", test_label1, len(test_label1))\n",
        "\n",
        "\n",
        "# 検証\n",
        "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
        "# 検証用データの誤り率\n",
        "print(\"Test Loss : \", score[0])\n",
        "# 検証用データの正確度\n",
        "print(\"Test Accuracy : \", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCquXF_HQbyC"
      },
      "source": [
        "## 活性化関数\n",
        "活性化関数は、入力信号の総和を出力信号に変換する関数です。この場合、入力の総和を求めるとき、一般には重みが付けられます。非線形関数が用いられ、先ほどはシグモイド関数が設定されていました。その他によく用いられる活性化関数として、ReLU（Rectified Linear Unit）があります。一応、シグモイド関数とReLU、その微分を図示しておきます。勾配降下法では活性化関数の微分をかける操作を行うのですが、シグモイド関数だとあまり大きな値は取りえません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "t6nm2GESRznw",
        "outputId": "18e1ca69-ad99-40d7-a604-8a1ddb1584a4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Sigmoid & ReLU\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "# Sigmoid\n",
        "def sigmoid_func(x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "# Sigmoidの導関数\n",
        "def sigmoid_grad(x):\n",
        "    y = sigmoid_func(x)\n",
        "    return (1 - y) * y\n",
        "\n",
        "#ReLU関数\n",
        "def relu_func(x):\n",
        "    return np.maximum(0, x) #0とxを比較して大きい方の数値を返す\n",
        "\n",
        "# ReLUの導関数\n",
        "def relu_grad(x):\n",
        "    return 1 * (x > 0)\n",
        "\n",
        "x = np.arange(-4, 4, 0.01)\n",
        "y_sigmoid = sigmoid_func(x)\n",
        "y_sig_grad = sigmoid_grad(x)\n",
        "z_relu = relu_func(x)\n",
        "z_relu_grad = relu_grad(x)\n",
        "\n",
        "plt.plot(x, y_sigmoid, label = \"Sigmoid\")\n",
        "plt.plot(x, y_sig_grad, label = \"Sigmoid_grad\")\n",
        "plt.plot(x, z_relu, label = \"ReLU\")\n",
        "plt.plot(x, z_relu_grad, label = \"ReLU_grad\")\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel(\"input\")\n",
        "plt.ylabel(\"output\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ioMRWhOYVxS"
      },
      "source": [
        "では、活性化関数をReLUに変更してみましょう。ニューラルネットワークの構成は先のものと同じです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSRNE2CfXBny",
        "outputId": "79f77dbb-39dd-41b0-def0-415cd2898d67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               200960    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(10000, 28, 28) (10000, 10)\n",
            "(1000, 28, 28) (1000, 10)\n",
            "Epoch 1/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 1.1870 - accuracy: 0.5657 - val_loss: 0.8443 - val_accuracy: 0.7170\n",
            "Epoch 2/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.7938 - accuracy: 0.7068 - val_loss: 0.6068 - val_accuracy: 0.7660\n",
            "Epoch 3/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.6922 - accuracy: 0.7481 - val_loss: 0.5128 - val_accuracy: 0.8110\n",
            "Epoch 4/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6396 - accuracy: 0.7659 - val_loss: 0.4562 - val_accuracy: 0.8450\n",
            "Epoch 5/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6038 - accuracy: 0.7775 - val_loss: 0.5125 - val_accuracy: 0.8130\n",
            "Epoch 6/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.5623 - accuracy: 0.7939 - val_loss: 0.4614 - val_accuracy: 0.8370\n",
            "Epoch 7/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.5501 - accuracy: 0.8040 - val_loss: 0.4621 - val_accuracy: 0.8260\n",
            "Epoch 8/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.5376 - accuracy: 0.8065 - val_loss: 0.4000 - val_accuracy: 0.8640\n",
            "Epoch 9/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.5163 - accuracy: 0.8134 - val_loss: 0.4048 - val_accuracy: 0.8640\n",
            "Epoch 10/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.5027 - accuracy: 0.8194 - val_loss: 0.3947 - val_accuracy: 0.8650\n",
            "Epoch 11/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4738 - accuracy: 0.8306 - val_loss: 0.4024 - val_accuracy: 0.8540\n",
            "Epoch 12/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 0.4698 - accuracy: 0.8282 - val_loss: 0.4443 - val_accuracy: 0.8460\n",
            "Epoch 13/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4657 - accuracy: 0.8317 - val_loss: 0.3955 - val_accuracy: 0.8770\n",
            "Epoch 14/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4594 - accuracy: 0.8329 - val_loss: 0.3718 - val_accuracy: 0.8740\n",
            "Epoch 15/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4468 - accuracy: 0.8398 - val_loss: 0.4121 - val_accuracy: 0.8460\n",
            "Epoch 16/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4361 - accuracy: 0.8429 - val_loss: 0.3847 - val_accuracy: 0.8570\n",
            "Epoch 17/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4373 - accuracy: 0.8445 - val_loss: 0.4013 - val_accuracy: 0.8510\n",
            "Epoch 18/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4206 - accuracy: 0.8430 - val_loss: 0.3732 - val_accuracy: 0.8620\n",
            "Epoch 19/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4096 - accuracy: 0.8503 - val_loss: 0.3856 - val_accuracy: 0.8730\n",
            "Epoch 20/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4179 - accuracy: 0.8486 - val_loss: 0.4983 - val_accuracy: 0.8250\n",
            "Epoch 21/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3992 - accuracy: 0.8511 - val_loss: 0.3760 - val_accuracy: 0.8700\n",
            "Epoch 22/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3936 - accuracy: 0.8546 - val_loss: 0.3622 - val_accuracy: 0.8710\n",
            "Epoch 23/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3925 - accuracy: 0.8585 - val_loss: 0.3595 - val_accuracy: 0.8810\n",
            "Epoch 24/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3867 - accuracy: 0.8587 - val_loss: 0.3417 - val_accuracy: 0.8830\n",
            "Epoch 25/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3788 - accuracy: 0.8630 - val_loss: 0.4001 - val_accuracy: 0.8560\n",
            "Epoch 26/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3723 - accuracy: 0.8643 - val_loss: 0.4550 - val_accuracy: 0.8430\n",
            "Epoch 27/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3747 - accuracy: 0.8606 - val_loss: 0.3406 - val_accuracy: 0.8940\n",
            "Epoch 28/30\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.3609 - accuracy: 0.8678 - val_loss: 0.3364 - val_accuracy: 0.8840\n",
            "Epoch 29/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3641 - accuracy: 0.8662 - val_loss: 0.4033 - val_accuracy: 0.8610\n",
            "Epoch 30/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3528 - accuracy: 0.8711 - val_loss: 0.3558 - val_accuracy: 0.8780\n",
            "uint8\n",
            "(2000, 28, 28)\n",
            "float32\n",
            "(2000, 28, 28)\n",
            "評価用データ\n",
            "0.0 - 1.0\n",
            "0 - 9\n",
            "検証用 [9 2 1 ... 3 6 0] 2000\n",
            "検証用 [[0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]] 2000\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8570\n",
            "Test Loss :  0.39650142192840576\n",
            "Test Accuracy :  0.8569999933242798\n"
          ]
        }
      ],
      "source": [
        "# ニューラルネットワークの構成----------------------------\n",
        "# Neural Network\n",
        "img_row = 28                # 入力層のユニット数\n",
        "img_col = 28\n",
        "unit_middle1 = 256          # 中間層のユニット数\n",
        "unit_middle2 = 128\n",
        "unit_output = 10            # 出力層のユニット数\n",
        "learning_rate = 0.1         # 学習係数\n",
        "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
        "batch_size = 64             # ミニバッチのサイズ\n",
        "\n",
        "\n",
        "# ニューラルネットワークの構築-----------------------------\n",
        "# keras.modelsからSequentialをインポート\n",
        "from tensorflow.keras.models import Sequential\n",
        "# keras.layersからDenseとFlattenをインポート\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout     # Dropoutを追加\n",
        "# keras.optimizersからSGDをインポート\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 入力層\n",
        "model.add(Flatten(input_shape = (img_row, img_col)))\n",
        "\n",
        "# 中間層\n",
        "model.add(Dense(unit_middle1, activation = \"relu\"))    # 中間層1\n",
        "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
        "model.add(Dense(unit_middle2, activation = \"relu\"))    # 中間層2\n",
        "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
        "\n",
        "# 出力層\n",
        "model.add(Dense(unit_output, activation = \"softmax\"))\n",
        "\n",
        "# モデルの概要を出力\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# モデルのコンパイル---------------------------------\n",
        "model.compile(\n",
        "    optimizer = SGD(learning_rate),            # SGD\n",
        "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
        "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
        ")\n",
        "\n",
        "\n",
        "# 学習を実行し、結果を出力する\n",
        "print(train_data1.shape, train_label1.shape)\n",
        "print(valid_data1.shape, valid_label1.shape)\n",
        "history = model.fit(train_data1,\n",
        "                    train_label1,\n",
        "                    epochs = epochs,\n",
        "                    batch_size = batch_size,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (valid_data1, valid_label1)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# 検証-----------------------------------------------\n",
        "# データ抽出\n",
        "test_data0 = test_data[0:2000, : , : ]\n",
        "test_label0 = test_label[0:2000]\n",
        "\n",
        "# データ型\n",
        "print(test_data0.dtype)\n",
        "print(test_data0.shape)\n",
        "\n",
        "# uint8 -> float32\n",
        "test_data1 = test_data0.astype(\"float32\") / 255\n",
        "\n",
        "# データ型\n",
        "print(test_data1.dtype)\n",
        "print(test_data1.shape)\n",
        "\n",
        "print(\"評価用データ\")\n",
        "print(test_data1.min(), \"-\", test_data1.max())\n",
        "print(test_label0.min(), \"-\", test_label0.max())\n",
        "\n",
        "\n",
        "# ラベルの表示\n",
        "print(\"検証用\", test_label0, len(test_label0))\n",
        "\n",
        "# one-hot vector\n",
        "test_label1 = to_categorical(test_label0)\n",
        "print(\"検証用\", test_label1, len(test_label1))\n",
        "\n",
        "\n",
        "# 検証\n",
        "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
        "# 検証用データの誤り率\n",
        "print(\"Test Loss : \", score[0])\n",
        "# 検証用データの正確度\n",
        "print(\"Test Accuracy : \", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufms0iFdeGkk"
      },
      "source": [
        "## 最適化関数\n",
        "最適化関数（optimizer）は、損失関数を重みで微分し、学習率や過去の重みの更新量を踏まえて、どのように重みの更新に反映するかを指定します。これまで、SGD（確率的勾配降下法）を設定していました。ここで、Adam（Adaptive Moment Estimation）を使ってみます。Adamは、振動抑制に移動平均するmomentumと、学習係数を調整するRMSPropとを組み合わせたような感じです。\n",
        "tensorflow.keras.optimizersからAdamをインポートし、model.compileのoptimizerに\"Adam\"を指定します。β1は一次モーメントの減衰率、β2は二次モーメントの減衰率です。この場合、学習係数を小さめに取らないと精度が出ません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywTXq4Oug1EW",
        "outputId": "2f84b930-51a1-49ad-d52b-d0cf9f1b795a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               200960    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(10000, 28, 28) (10000, 10)\n",
            "(1000, 28, 28) (1000, 10)\n",
            "Epoch 1/30\n",
            "157/157 [==============================] - 2s 6ms/step - loss: 1.1565 - accuracy: 0.5869 - val_loss: 0.5958 - val_accuracy: 0.8010\n",
            "Epoch 2/30\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.7307 - accuracy: 0.7359 - val_loss: 0.4880 - val_accuracy: 0.8480\n",
            "Epoch 3/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.6327 - accuracy: 0.7633 - val_loss: 0.4620 - val_accuracy: 0.8410\n",
            "Epoch 4/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.5806 - accuracy: 0.7892 - val_loss: 0.4345 - val_accuracy: 0.8410\n",
            "Epoch 5/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.5478 - accuracy: 0.7995 - val_loss: 0.4155 - val_accuracy: 0.8650\n",
            "Epoch 6/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.5258 - accuracy: 0.8078 - val_loss: 0.3867 - val_accuracy: 0.8720\n",
            "Epoch 7/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.5029 - accuracy: 0.8156 - val_loss: 0.3982 - val_accuracy: 0.8690\n",
            "Epoch 8/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4836 - accuracy: 0.8235 - val_loss: 0.3826 - val_accuracy: 0.8760\n",
            "Epoch 9/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4637 - accuracy: 0.8289 - val_loss: 0.3662 - val_accuracy: 0.8810\n",
            "Epoch 10/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.4524 - accuracy: 0.8386 - val_loss: 0.3546 - val_accuracy: 0.8780\n",
            "Epoch 11/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.4408 - accuracy: 0.8397 - val_loss: 0.3519 - val_accuracy: 0.8840\n",
            "Epoch 12/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.4339 - accuracy: 0.8436 - val_loss: 0.3689 - val_accuracy: 0.8660\n",
            "Epoch 13/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4341 - accuracy: 0.8391 - val_loss: 0.3457 - val_accuracy: 0.8900\n",
            "Epoch 14/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4113 - accuracy: 0.8505 - val_loss: 0.3411 - val_accuracy: 0.8840\n",
            "Epoch 15/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4045 - accuracy: 0.8516 - val_loss: 0.3335 - val_accuracy: 0.8850\n",
            "Epoch 16/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.4005 - accuracy: 0.8503 - val_loss: 0.3639 - val_accuracy: 0.8840\n",
            "Epoch 17/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3923 - accuracy: 0.8588 - val_loss: 0.3440 - val_accuracy: 0.8830\n",
            "Epoch 18/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3906 - accuracy: 0.8570 - val_loss: 0.3416 - val_accuracy: 0.8820\n",
            "Epoch 19/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3851 - accuracy: 0.8595 - val_loss: 0.3297 - val_accuracy: 0.8910\n",
            "Epoch 20/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3809 - accuracy: 0.8593 - val_loss: 0.3482 - val_accuracy: 0.8850\n",
            "Epoch 21/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3729 - accuracy: 0.8599 - val_loss: 0.3533 - val_accuracy: 0.8860\n",
            "Epoch 22/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3663 - accuracy: 0.8655 - val_loss: 0.3417 - val_accuracy: 0.8910\n",
            "Epoch 23/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3615 - accuracy: 0.8674 - val_loss: 0.3382 - val_accuracy: 0.8790\n",
            "Epoch 24/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3595 - accuracy: 0.8655 - val_loss: 0.3250 - val_accuracy: 0.8870\n",
            "Epoch 25/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3501 - accuracy: 0.8686 - val_loss: 0.3329 - val_accuracy: 0.8930\n",
            "Epoch 26/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3405 - accuracy: 0.8770 - val_loss: 0.3319 - val_accuracy: 0.8930\n",
            "Epoch 27/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3422 - accuracy: 0.8709 - val_loss: 0.3291 - val_accuracy: 0.8950\n",
            "Epoch 28/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3444 - accuracy: 0.8689 - val_loss: 0.3234 - val_accuracy: 0.8940\n",
            "Epoch 29/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3411 - accuracy: 0.8685 - val_loss: 0.3236 - val_accuracy: 0.9030\n",
            "Epoch 30/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3321 - accuracy: 0.8752 - val_loss: 0.3367 - val_accuracy: 0.8840\n",
            "uint8\n",
            "(2000, 28, 28)\n",
            "float32\n",
            "(2000, 28, 28)\n",
            "評価用データ\n",
            "0.0 - 1.0\n",
            "0 - 9\n",
            "検証用 [9 2 1 ... 3 6 0] 2000\n",
            "検証用 [[0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]] 2000\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8585\n",
            "Test Loss :  0.3926459848880768\n",
            "Test Accuracy :  0.8585000038146973\n"
          ]
        }
      ],
      "source": [
        "# ニューラルネットワークの構成----------------------------\n",
        "# Neural Network\n",
        "img_row = 28                # 入力層のユニット数\n",
        "img_col = 28\n",
        "unit_middle1 = 256          # 中間層のユニット数\n",
        "unit_middle2 = 128\n",
        "unit_output = 10            # 出力層のユニット数\n",
        "learning_rate = 0.001         # 学習係数\n",
        "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
        "batch_size = 64             # ミニバッチのサイズ\n",
        "\n",
        "\n",
        "# ニューラルネットワークの構築-----------------------------\n",
        "# keras.modelsからSequentialをインポート\n",
        "from tensorflow.keras.models import Sequential\n",
        "# keras.layersからDenseとFlattenをインポート\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout     # Dropoutを追加\n",
        "# keras.optimizersからSGDをインポート\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 入力層\n",
        "model.add(Flatten(input_shape = (img_row, img_col)))\n",
        "\n",
        "# 中間層\n",
        "model.add(Dense(unit_middle1, activation = \"relu\"))    # 中間層1\n",
        "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
        "model.add(Dense(unit_middle2, activation = \"relu\"))    # 中間層2\n",
        "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
        "\n",
        "# 出力層\n",
        "model.add(Dense(unit_output, activation = \"softmax\"))\n",
        "\n",
        "# モデルの概要を出力\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# モデルのコンパイル---------------------------------\n",
        "model.compile(\n",
        "    optimizer = Adam(learning_rate, beta_1=0.9, beta_2=0.999),   # Adam\n",
        "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
        "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
        ")\n",
        "\n",
        "\n",
        "# 学習を実行し、結果を出力する\n",
        "print(train_data1.shape, train_label1.shape)\n",
        "print(valid_data1.shape, valid_label1.shape)\n",
        "history = model.fit(train_data1,\n",
        "                    train_label1,\n",
        "                    epochs = epochs,\n",
        "                    batch_size = batch_size,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (valid_data1, valid_label1)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# 検証-----------------------------------------------\n",
        "# データ抽出\n",
        "test_data0 = test_data[0:2000, : , : ]\n",
        "test_label0 = test_label[0:2000]\n",
        "\n",
        "# データ型\n",
        "print(test_data0.dtype)\n",
        "print(test_data0.shape)\n",
        "\n",
        "# uint8 -> float32\n",
        "test_data1 = test_data0.astype(\"float32\") / 255\n",
        "\n",
        "# データ型\n",
        "print(test_data1.dtype)\n",
        "print(test_data1.shape)\n",
        "\n",
        "print(\"評価用データ\")\n",
        "print(test_data1.min(), \"-\", test_data1.max())\n",
        "print(test_label0.min(), \"-\", test_label0.max())\n",
        "\n",
        "\n",
        "# ラベルの表示\n",
        "print(\"検証用\", test_label0, len(test_label0))\n",
        "\n",
        "# one-hot vector\n",
        "test_label1 = to_categorical(test_label0)\n",
        "print(\"検証用\", test_label1, len(test_label1))\n",
        "\n",
        "\n",
        "# 検証\n",
        "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
        "# 検証用データの誤り率\n",
        "print(\"Test Loss : \", score[0])\n",
        "# 検証用データの正確度\n",
        "print(\"Test Accuracy : \", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdDJotS0kCRl"
      },
      "source": [
        "## 学習係数\n",
        "学習係数は学習率とも呼ばれ、ネットワークの層の重みをどのくらい変更するかを決めるものです。損失関数に対して適切な学習係数を設定することは極めて重要です。Adamの特別な場合がSGDと考えることもできますから、最適化関数を\"SGD\"に戻します。ただし、学習係数を\"0.001\"に設定しています。重みの更新量が少なくなりますので、\"epochs = 30\"では収束しきらないようです（収束に時間がかかる）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44FT54GcqbHg",
        "outputId": "30f3ce10-acf8-474f-f0f9-595b72b1a1ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(10000, 28, 28) (10000, 10)\n",
            "(1000, 28, 28) (1000, 10)\n",
            "Epoch 1/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 2.4042 - accuracy: 0.1302 - val_loss: 2.1255 - val_accuracy: 0.2770\n",
            "Epoch 2/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 2.2025 - accuracy: 0.1824 - val_loss: 1.9912 - val_accuracy: 0.4050\n",
            "Epoch 3/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 2.0805 - accuracy: 0.2400 - val_loss: 1.8855 - val_accuracy: 0.5000\n",
            "Epoch 4/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 1.9878 - accuracy: 0.2817 - val_loss: 1.7911 - val_accuracy: 0.5430\n",
            "Epoch 5/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.9169 - accuracy: 0.3225 - val_loss: 1.7076 - val_accuracy: 0.5730\n",
            "Epoch 6/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.8412 - accuracy: 0.3543 - val_loss: 1.6279 - val_accuracy: 0.5900\n",
            "Epoch 7/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.7624 - accuracy: 0.3924 - val_loss: 1.5532 - val_accuracy: 0.5960\n",
            "Epoch 8/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.7209 - accuracy: 0.3995 - val_loss: 1.4883 - val_accuracy: 0.6090\n",
            "Epoch 9/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.6622 - accuracy: 0.4207 - val_loss: 1.4259 - val_accuracy: 0.6240\n",
            "Epoch 10/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.6039 - accuracy: 0.4388 - val_loss: 1.3696 - val_accuracy: 0.6270\n",
            "Epoch 11/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 1.5779 - accuracy: 0.4463 - val_loss: 1.3205 - val_accuracy: 0.6280\n",
            "Epoch 12/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.5441 - accuracy: 0.4551 - val_loss: 1.2756 - val_accuracy: 0.6390\n",
            "Epoch 13/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.4953 - accuracy: 0.4800 - val_loss: 1.2333 - val_accuracy: 0.6420\n",
            "Epoch 14/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.4586 - accuracy: 0.4803 - val_loss: 1.1941 - val_accuracy: 0.6440\n",
            "Epoch 15/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.4324 - accuracy: 0.4983 - val_loss: 1.1596 - val_accuracy: 0.6520\n",
            "Epoch 16/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.3960 - accuracy: 0.5070 - val_loss: 1.1260 - val_accuracy: 0.6570\n",
            "Epoch 17/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.3821 - accuracy: 0.5051 - val_loss: 1.0961 - val_accuracy: 0.6620\n",
            "Epoch 18/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.3445 - accuracy: 0.5214 - val_loss: 1.0705 - val_accuracy: 0.6640\n",
            "Epoch 19/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.3262 - accuracy: 0.5215 - val_loss: 1.0459 - val_accuracy: 0.6680\n",
            "Epoch 20/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.2945 - accuracy: 0.5369 - val_loss: 1.0215 - val_accuracy: 0.6700\n",
            "Epoch 21/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.2811 - accuracy: 0.5447 - val_loss: 1.0013 - val_accuracy: 0.6760\n",
            "Epoch 22/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.2481 - accuracy: 0.5600 - val_loss: 0.9795 - val_accuracy: 0.6910\n",
            "Epoch 23/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 1.2240 - accuracy: 0.5586 - val_loss: 0.9606 - val_accuracy: 0.6880\n",
            "Epoch 24/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 1.2199 - accuracy: 0.5620 - val_loss: 0.9445 - val_accuracy: 0.6930\n",
            "Epoch 25/30\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 1.2088 - accuracy: 0.5639 - val_loss: 0.9301 - val_accuracy: 0.6970\n",
            "Epoch 26/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.1958 - accuracy: 0.5718 - val_loss: 0.9172 - val_accuracy: 0.7030\n",
            "Epoch 27/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.1709 - accuracy: 0.5824 - val_loss: 0.9027 - val_accuracy: 0.7080\n",
            "Epoch 28/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.1592 - accuracy: 0.5840 - val_loss: 0.8907 - val_accuracy: 0.7100\n",
            "Epoch 29/30\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.1461 - accuracy: 0.5869 - val_loss: 0.8797 - val_accuracy: 0.7160\n",
            "Epoch 30/30\n",
            "157/157 [==============================] - 1s 3ms/step - loss: 1.1282 - accuracy: 0.5954 - val_loss: 0.8676 - val_accuracy: 0.7140\n",
            "uint8\n",
            "(2000, 28, 28)\n",
            "float32\n",
            "(2000, 28, 28)\n",
            "評価用データ\n",
            "0.0 - 1.0\n",
            "0 - 9\n",
            "検証用 [9 2 1 ... 3 6 0] 2000\n",
            "検証用 [[0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]] 2000\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8878 - accuracy: 0.7015\n",
            "Test Loss :  0.8877738118171692\n",
            "Test Accuracy :  0.7014999985694885\n"
          ]
        }
      ],
      "source": [
        "# ニューラルネットワークの構成----------------------------\n",
        "# Neural Network\n",
        "img_row = 28                # 入力層のユニット数\n",
        "img_col = 28\n",
        "unit_middle1 = 256          # 中間層のユニット数\n",
        "unit_middle2 = 128\n",
        "unit_output = 10            # 出力層のユニット数\n",
        "learning_rate = 0.001         # 学習係数\n",
        "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
        "batch_size = 64             # ミニバッチのサイズ\n",
        "\n",
        "\n",
        "# ニューラルネットワークの構築-----------------------------\n",
        "# keras.modelsからSequentialをインポート\n",
        "from tensorflow.keras.models import Sequential\n",
        "# keras.layersからDenseとFlattenをインポート\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout     # Dropoutを追加\n",
        "# keras.optimizersからSGDをインポート\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 入力層\n",
        "model.add(Flatten(input_shape = (img_row, img_col)))\n",
        "\n",
        "# 中間層\n",
        "model.add(Dense(unit_middle1, activation = \"relu\"))    # 中間層1\n",
        "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
        "model.add(Dense(unit_middle2, activation = \"relu\"))    # 中間層2\n",
        "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
        "\n",
        "# 出力層\n",
        "model.add(Dense(unit_output, activation = \"softmax\"))\n",
        "\n",
        "# モデルの概要を出力\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# モデルのコンパイル---------------------------------\n",
        "model.compile(\n",
        "    optimizer = SGD(learning_rate),            # SGD\n",
        "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
        "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
        ")\n",
        "\n",
        "\n",
        "# 学習を実行し、結果を出力する\n",
        "print(train_data1.shape, train_label1.shape)\n",
        "print(valid_data1.shape, valid_label1.shape)\n",
        "history = model.fit(train_data1,\n",
        "                    train_label1,\n",
        "                    epochs = epochs,\n",
        "                    batch_size = batch_size,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (valid_data1, valid_label1)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# 検証-----------------------------------------------\n",
        "# データ抽出\n",
        "test_data0 = test_data[0:2000, : , : ]\n",
        "test_label0 = test_label[0:2000]\n",
        "\n",
        "# データ型\n",
        "print(test_data0.dtype)\n",
        "print(test_data0.shape)\n",
        "\n",
        "# uint8 -> float32\n",
        "test_data1 = test_data0.astype(\"float32\") / 255\n",
        "\n",
        "# データ型\n",
        "print(test_data1.dtype)\n",
        "print(test_data1.shape)\n",
        "\n",
        "print(\"評価用データ\")\n",
        "print(test_data1.min(), \"-\", test_data1.max())\n",
        "print(test_label0.min(), \"-\", test_label0.max())\n",
        "\n",
        "\n",
        "# ラベルの表示\n",
        "print(\"検証用\", test_label0, len(test_label0))\n",
        "\n",
        "# one-hot vector\n",
        "test_label1 = to_categorical(test_label0)\n",
        "print(\"検証用\", test_label1, len(test_label1))\n",
        "\n",
        "\n",
        "# 検証\n",
        "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
        "# 検証用データの誤り率\n",
        "print(\"Test Loss : \", score[0])\n",
        "# 検証用データの正確度\n",
        "print(\"Test Accuracy : \", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZPI4txXq-cx"
      },
      "source": [
        "## ミニバッチ学習\n",
        "ニューラルネットワークのモデルを学習するとき、モデルに与える学習データの数をバッチサイズといいます。このバッチサイズで学習（ミニバッチ学習）を行い、損失関数の勾配を求めて重みの更新を行います。バッチサイズの難しさは他のパラメータと関係している点にあります。バッチサイズは主に、データ1個に対する感度、1エポックの計算時間、メモリ使用量にきいてきます。バッチサイズが小さいと、1つのデータに反応しやすくなります（この場合、学習係数を調整する）。バッチサイズが大きいと、データ全体の特徴を捉える感じになります。バッチサイズが小さいと、重み更新の回数は多くなりますから計算時間はかかります。バッチサイズの単位でデータを読みますから、バッチサイズが小さい方が、メモリ使用量は少なくて済みます。以下ではバッチサイズを\"batch_size = 32\"に設定します（学習係数は\"0.1\"に戻す）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zcoZdX7y_lT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab96ef2-6f48-4ed9-f825-14c1766a2a79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(10000, 28, 28) (10000, 10)\n",
            "(1000, 28, 28) (1000, 10)\n",
            "Epoch 1/30\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 1.0662 - accuracy: 0.6122 - val_loss: 0.6628 - val_accuracy: 0.7350\n",
            "Epoch 2/30\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7406 - accuracy: 0.7255 - val_loss: 0.5094 - val_accuracy: 0.8070\n",
            "Epoch 3/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6556 - accuracy: 0.7588 - val_loss: 0.4594 - val_accuracy: 0.8420\n",
            "Epoch 4/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6124 - accuracy: 0.7756 - val_loss: 0.4690 - val_accuracy: 0.8370\n",
            "Epoch 5/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5772 - accuracy: 0.7874 - val_loss: 0.4251 - val_accuracy: 0.8540\n",
            "Epoch 6/30\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5598 - accuracy: 0.7982 - val_loss: 0.4477 - val_accuracy: 0.8160\n",
            "Epoch 7/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5277 - accuracy: 0.8069 - val_loss: 0.4195 - val_accuracy: 0.8390\n",
            "Epoch 8/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5148 - accuracy: 0.8086 - val_loss: 0.4840 - val_accuracy: 0.8180\n",
            "Epoch 9/30\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4915 - accuracy: 0.8196 - val_loss: 0.3880 - val_accuracy: 0.8770\n",
            "Epoch 10/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4859 - accuracy: 0.8217 - val_loss: 0.3882 - val_accuracy: 0.8550\n",
            "Epoch 11/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4659 - accuracy: 0.8303 - val_loss: 0.3707 - val_accuracy: 0.8800\n",
            "Epoch 12/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4654 - accuracy: 0.8293 - val_loss: 0.3864 - val_accuracy: 0.8740\n",
            "Epoch 13/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4531 - accuracy: 0.8357 - val_loss: 0.4487 - val_accuracy: 0.8180\n",
            "Epoch 14/30\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.4420 - accuracy: 0.8376 - val_loss: 0.3792 - val_accuracy: 0.8730\n",
            "Epoch 15/30\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4412 - accuracy: 0.8341 - val_loss: 0.3922 - val_accuracy: 0.8710\n",
            "Epoch 16/30\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4385 - accuracy: 0.8416 - val_loss: 0.3680 - val_accuracy: 0.8740\n",
            "Epoch 17/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4182 - accuracy: 0.8464 - val_loss: 0.3625 - val_accuracy: 0.8810\n",
            "Epoch 18/30\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4172 - accuracy: 0.8443 - val_loss: 0.3576 - val_accuracy: 0.8820\n",
            "Epoch 19/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4073 - accuracy: 0.8467 - val_loss: 0.3564 - val_accuracy: 0.8760\n",
            "Epoch 20/30\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4003 - accuracy: 0.8511 - val_loss: 0.3739 - val_accuracy: 0.8760\n",
            "Epoch 21/30\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4097 - accuracy: 0.8516 - val_loss: 0.3971 - val_accuracy: 0.8560\n",
            "Epoch 22/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3962 - accuracy: 0.8533 - val_loss: 0.3573 - val_accuracy: 0.8850\n",
            "Epoch 23/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3934 - accuracy: 0.8514 - val_loss: 0.4244 - val_accuracy: 0.8540\n",
            "Epoch 24/30\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3874 - accuracy: 0.8571 - val_loss: 0.3760 - val_accuracy: 0.8690\n",
            "Epoch 25/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3839 - accuracy: 0.8592 - val_loss: 0.3514 - val_accuracy: 0.8780\n",
            "Epoch 26/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3825 - accuracy: 0.8554 - val_loss: 0.3563 - val_accuracy: 0.8780\n",
            "Epoch 27/30\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.3735 - accuracy: 0.8604 - val_loss: 0.3554 - val_accuracy: 0.8840\n",
            "Epoch 28/30\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3617 - accuracy: 0.8683 - val_loss: 0.3899 - val_accuracy: 0.8690\n",
            "Epoch 29/30\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3578 - accuracy: 0.8659 - val_loss: 0.4115 - val_accuracy: 0.8680\n",
            "Epoch 30/30\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3661 - accuracy: 0.8661 - val_loss: 0.3418 - val_accuracy: 0.8830\n",
            "uint8\n",
            "(2000, 28, 28)\n",
            "float32\n",
            "(2000, 28, 28)\n",
            "評価用データ\n",
            "0.0 - 1.0\n",
            "0 - 9\n",
            "検証用 [9 2 1 ... 3 6 0] 2000\n",
            "検証用 [[0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]] 2000\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8670\n",
            "Test Loss :  0.38915807008743286\n",
            "Test Accuracy :  0.8669999837875366\n"
          ]
        }
      ],
      "source": [
        "# ニューラルネットワークの構成----------------------------\n",
        "# Neural Network\n",
        "img_row = 28                # 入力層のユニット数\n",
        "img_col = 28\n",
        "unit_middle1 = 256          # 中間層のユニット数\n",
        "unit_middle2 = 128\n",
        "unit_output = 10            # 出力層のユニット数\n",
        "learning_rate = 0.1         # 学習係数\n",
        "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
        "batch_size = 32             # ミニバッチのサイズ\n",
        "\n",
        "\n",
        "# ニューラルネットワークの構築-----------------------------\n",
        "# keras.modelsからSequentialをインポート\n",
        "from tensorflow.keras.models import Sequential\n",
        "# keras.layersからDenseとFlattenをインポート\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout     # Dropoutを追加\n",
        "# keras.optimizersからSGDをインポート\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 入力層\n",
        "model.add(Flatten(input_shape = (img_row, img_col)))\n",
        "\n",
        "# 中間層\n",
        "model.add(Dense(unit_middle1, activation = \"relu\"))    # 中間層1\n",
        "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
        "model.add(Dense(unit_middle2, activation = \"relu\"))    # 中間層2\n",
        "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
        "\n",
        "# 出力層\n",
        "model.add(Dense(unit_output, activation = \"softmax\"))\n",
        "\n",
        "# モデルの概要を出力\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# モデルのコンパイル---------------------------------\n",
        "model.compile(\n",
        "    optimizer = SGD(learning_rate),            # SGD\n",
        "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
        "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
        ")\n",
        "\n",
        "\n",
        "# 学習を実行し、結果を出力する\n",
        "print(train_data1.shape, train_label1.shape)\n",
        "print(valid_data1.shape, valid_label1.shape)\n",
        "history = model.fit(train_data1,\n",
        "                    train_label1,\n",
        "                    epochs = epochs,\n",
        "                    batch_size = batch_size,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (valid_data1, valid_label1)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# 検証-----------------------------------------------\n",
        "# データ抽出\n",
        "test_data0 = test_data[0:2000, : , : ]\n",
        "test_label0 = test_label[0:2000]\n",
        "\n",
        "# データ型\n",
        "print(test_data0.dtype)\n",
        "print(test_data0.shape)\n",
        "\n",
        "# uint8 -> float32\n",
        "test_data1 = test_data0.astype(\"float32\") / 255\n",
        "\n",
        "# データ型\n",
        "print(test_data1.dtype)\n",
        "print(test_data1.shape)\n",
        "\n",
        "print(\"評価用データ\")\n",
        "print(test_data1.min(), \"-\", test_data1.max())\n",
        "print(test_label0.min(), \"-\", test_label0.max())\n",
        "\n",
        "\n",
        "# ラベルの表示\n",
        "print(\"検証用\", test_label0, len(test_label0))\n",
        "\n",
        "# one-hot vector\n",
        "test_label1 = to_categorical(test_label0)\n",
        "print(\"検証用\", test_label1, len(test_label1))\n",
        "\n",
        "\n",
        "# 検証\n",
        "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
        "# 検証用データの誤り率\n",
        "print(\"Test Loss : \", score[0])\n",
        "# 検証用データの正確度\n",
        "print(\"Test Accuracy : \", score[1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}