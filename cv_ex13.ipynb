{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEQF3J2fb6RN"
   },
   "source": [
    "第13回の演習です。前回、Kerasで構築したニューラルネットワークに対して、ハイパーパラメータを調整します。\n",
    "左上の「ファイル」＞「ドライブにコピーを保存」を選択して、Google DriveにNotebookを保存します。ご自身のGoogleドライブの\"Colab Notebooks\"フォルダで、保存したNotebookを右クリックし、「アプリで開く」＞「Google Colaboratory」を選択します。その上で、各コードを実行するには、以下のコマンドを実行してください。実行は「再生」ボタンを押します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arnzzHVKbsJ_",
    "outputId": "933fb88d-3f88-4a3e-ba09-b4230685fd87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 13\n"
     ]
    }
   ],
   "source": [
    "print(\"Chapter 13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TumMt-4e4YFi"
   },
   "source": [
    "# ニューラルネットワークのハイパーパラメータの調整\n",
    "前回、Kerasでニューラルネットワークを構築し、Fashion-MNISTデータセットのアイテム画像を認識しました。ところが、その正確度（識別率）は80%弱で、scikit-learnライブラリのニューラルネットワークよりも悪化しています。これは未だ、ハイパーパラメータの調整をやっていないからです。そこで、ハイパーパラメータを調整していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRssDCF7zLsI"
   },
   "source": [
    "## GPUの利用\n",
    "時間がかかるので、GPUを使います。Coogle Colaboratoryのメニュー「ランライム」をクリックし、「ランタイムのタイプを変更」を選択します。「ハードウェアアクセラレータ」を\"GPU\"に変更します。これで計算処理が多少速く終了するようになるでしょう。ただ、「Colabでの使用量上限に達したため、現在GPUに接続できません」というメッセージが出ると、GPUが割り当てられないこともあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzWfed7WaY-z"
   },
   "source": [
    "## データセットの用意と前処理\n",
    "まずはデータセットを用意し、前処理を済ませます。これらはこの回では共通の操作ですので、一度実行しておけばよいでしょう。ただし、「ランタイムリセット」されてしまったら再実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spOFM6SdBVVE",
    "outputId": "70788378-2b5a-4bac-84c2-cfe961c373cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "uint8 uint8\n",
      "(10000, 28, 28) (1000, 28, 28)\n",
      "float32 float32\n",
      "(10000, 28, 28) (1000, 28, 28)\n",
      "学習用データ\n",
      "0.0 - 1.0\n",
      "0 - 9\n",
      "検証用データ\n",
      "0.0 - 1.0\n",
      "0 - 9\n",
      "学習用 [9 0 0 ... 0 6 6] 10000\n",
      "検証用 [8 7 6 8 7 7 2 0 5 3 5 5 1 3 9 4 1 9 3 2 8 2 9 3 4 5 1 0 3 2 8 5 3 8 2 2 9\n",
      " 7 7 9 9 1 2 6 7 6 6 6 6 7 3 7 8 5 9 5 9 1 5 9 8 3 6 1 1 0 3 3 1 2 9 8 9 5\n",
      " 1 0 6 2 3 0 0 8 8 5 7 3 6 9 7 3 6 4 8 5 0 8 3 6 7 1 5 1 7 6 4 1 6 9 8 1 1\n",
      " 7 7 0 7 4 9 4 2 9 9 9 6 5 2 3 5 6 5 1 9 6 1 5 6 9 3 5 3 5 3 2 7 0 9 1 1 2\n",
      " 1 3 6 4 8 4 1 3 2 6 2 0 9 5 8 6 5 5 6 8 0 8 3 9 6 9 8 3 2 5 8 3 9 0 9 9 8\n",
      " 1 3 8 4 9 9 0 3 0 0 6 7 8 6 6 4 6 3 9 0 4 6 7 2 5 6 2 9 7 0 2 2 3 8 4 7 6\n",
      " 8 7 3 6 2 1 3 7 0 4 7 7 5 9 4 9 4 7 1 5 4 6 2 7 1 6 1 4 5 5 8 2 9 9 9 4 7\n",
      " 7 5 2 0 9 1 5 0 4 9 6 8 8 3 3 6 2 6 4 5 8 0 5 2 3 4 9 2 8 5 7 4 4 0 5 3 5\n",
      " 3 5 3 0 0 4 5 0 1 7 6 7 9 0 8 1 4 9 0 6 9 8 8 9 2 9 3 4 2 2 5 9 9 4 1 9 4\n",
      " 4 5 1 9 2 6 1 2 5 7 3 9 9 2 2 7 1 5 0 9 6 6 4 5 4 4 1 1 6 8 0 7 9 2 3 0 8\n",
      " 7 3 2 2 5 3 5 5 0 8 1 4 5 1 8 6 1 1 0 1 5 1 9 5 9 1 0 4 9 5 9 2 6 3 7 7 3\n",
      " 7 2 8 1 5 0 2 8 3 6 6 1 0 8 1 3 5 5 1 4 8 9 3 0 3 3 5 6 4 6 1 3 0 0 7 5 2\n",
      " 9 2 8 0 4 2 2 0 7 9 7 7 6 4 0 3 3 6 2 0 4 5 8 1 3 5 9 6 6 0 6 5 8 8 4 7 6\n",
      " 2 7 3 4 1 5 8 5 5 2 8 3 3 0 7 8 4 1 4 3 1 3 8 1 9 3 4 9 8 0 6 1 1 4 4 5 3\n",
      " 2 4 0 7 9 2 4 9 9 9 0 7 1 3 7 4 3 4 3 1 3 5 1 9 1 7 3 3 8 3 8 4 9 1 0 1 2\n",
      " 5 3 9 7 4 6 0 0 2 2 3 1 3 0 1 2 9 7 1 0 5 1 9 1 3 5 8 7 4 8 4 5 6 3 7 5 7\n",
      " 3 8 1 4 7 5 2 0 4 2 8 7 7 4 9 2 3 6 9 6 7 3 5 2 9 9 2 6 0 6 6 4 7 3 5 7 2\n",
      " 0 0 6 9 6 1 3 0 4 2 1 3 4 9 5 9 4 8 0 5 8 8 0 4 6 2 0 4 7 8 8 4 7 7 4 5 5\n",
      " 4 1 7 9 4 1 8 5 3 3 0 5 7 9 7 1 0 2 6 5 2 5 9 9 2 1 9 5 6 8 2 5 5 0 3 6 4\n",
      " 0 1 6 2 5 5 7 7 6 8 2 6 7 1 7 9 2 9 3 8 8 8 0 9 0 6 3 1 1 9 6 9 2 9 5 9 9\n",
      " 9 2 8 3 6 8 6 5 8 9 5 6 3 7 8 7 5 8 7 6 3 7 2 9 8 0 2 1 0 6 1 6 5 6 4 2 8\n",
      " 1 9 2 9 5 6 4 8 2 3 9 4 3 3 9 0 1 5 6 4 6 5 3 3 6 7 9 7 1 3 7 8 4 8 4 3 6\n",
      " 6 4 4 3 2 4 4 9 7 5 9 9 3 0 2 6 7 6 8 0 2 2 9 6 0 1 9 3 3 9 0 9 1 4 5 4 4\n",
      " 9 7 8 7 5 0 4 4 8 8 5 7 4 8 9 3 9 4 6 7 8 9 0 5 6 2 2 3 5 4 4 3 7 8 2 5 6\n",
      " 6 1 8 7 2 4 2 8 4 0 2 2 7 4 0 9 9 1 3 5 4 7 3 8 5 3 6 9 6 1 9 7 0 4 0 8 2\n",
      " 7 6 6 0 4 8 6 2 5 8 4 7 0 8 2 3 8 8 3 6 4 2 5 0 0 5 1 9 8 5 8 8 7 3 5 9 8\n",
      " 2 1 9 2 3 4 8 3 6 8 0 7 3 6 6 7 3 8 1 0 1 4 0 2 0 8 8 7 8 6 5 6 9 6 9 2 5\n",
      " 5] 1000\n",
      "学習用 [[0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] 10000\n",
      "検証用 [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] 1000\n"
     ]
    }
   ],
   "source": [
    "# Fashion-MNISTデータセット\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(train_data, train_label), (test_data, test_label) = fashion_mnist.load_data()\n",
    "\n",
    "# Fashion-MNISTのデータ形状\n",
    "print(train_data.shape)         # 学習用データ\n",
    "print(train_label.shape)        # 学習用データのラベル\n",
    "print(test_data.shape)          # 検証用データ\n",
    "print(test_label.shape)         # 検証用データのラベル\n",
    "\n",
    "\n",
    "# データの形状を確認------------------------------\n",
    "import numpy as np\n",
    "# データ抽出\n",
    "train_data0 = train_data[0:10000, : , : ]\n",
    "train_label0 = train_label[0:10000]\n",
    "valid_data0 = train_data[10000:11000, : , : ]\n",
    "valid_label0 = train_label[10000:11000]\n",
    "\n",
    "# データ型\n",
    "print(train_data0.dtype, valid_data0.dtype)\n",
    "print(train_data0.shape, valid_data0.shape)\n",
    "\n",
    "# uint8 -> float32\n",
    "train_data1 = train_data0.astype(\"float32\") / 255\n",
    "valid_data1 = valid_data0.astype(\"float32\") / 255\n",
    "\n",
    "# データ型\n",
    "print(train_data1.dtype, valid_data1.dtype)\n",
    "print(train_data1.shape, valid_data1.shape)\n",
    "\n",
    "print(\"学習用データ\")\n",
    "print(train_data1.min(), \"-\", train_data1.max())\n",
    "print(train_label0.min(), \"-\", train_label0.max())\n",
    "print(\"検証用データ\")\n",
    "print(valid_data1.min(), \"-\", valid_data1.max())\n",
    "print(valid_label0.min(), \"-\", valid_label0.max())\n",
    "\n",
    "\n",
    "# one-hotベクトルに変換----------------------\n",
    "# keras.utilsからto_categoricalをインポート\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ラベルの表示\n",
    "print(\"学習用\", train_label0, len(train_label0))\n",
    "print(\"検証用\", valid_label0, len(valid_label0))\n",
    "\n",
    "# one-hot vector\n",
    "train_label1 = to_categorical(train_label0)\n",
    "valid_label1 = to_categorical(valid_label0)\n",
    "\n",
    "print(\"学習用\", train_label1, len(train_label1))\n",
    "print(\"検証用\", valid_label1, len(valid_label1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8QGwZrvZeeT"
   },
   "source": [
    "## ネットワークの中間層を増やす\n",
    "前回のニューラルネットワークの構成に対して中間層を幾つか追加し、層を少しだけ深くすることから始めましょう。以下のプログラムコードは前回のものと同じですが、ネットワークの中間層を1層増やしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rE_2-3XZ4Ix",
    "outputId": "842d0da9-8c33-48e5-ff08-2757fc30f890"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28) (10000, 10)\n",
      "(1000, 28, 28) (1000, 10)\n",
      "Epoch 1/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2093 - loss: 2.2143 - val_accuracy: 0.5530 - val_loss: 1.5997\n",
      "Epoch 2/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5477 - loss: 1.4450 - val_accuracy: 0.5520 - val_loss: 1.1615\n",
      "Epoch 3/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6524 - loss: 1.0726 - val_accuracy: 0.6660 - val_loss: 0.9347\n",
      "Epoch 4/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6893 - loss: 0.8918 - val_accuracy: 0.7320 - val_loss: 0.8041\n",
      "Epoch 5/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.7880 - val_accuracy: 0.7310 - val_loss: 0.7259\n",
      "Epoch 6/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.7263 - val_accuracy: 0.7500 - val_loss: 0.6847\n",
      "Epoch 7/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7525 - loss: 0.6665 - val_accuracy: 0.7720 - val_loss: 0.6486\n",
      "Epoch 8/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7628 - loss: 0.6453 - val_accuracy: 0.7920 - val_loss: 0.6044\n",
      "Epoch 9/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7727 - loss: 0.6124 - val_accuracy: 0.7880 - val_loss: 0.5874\n",
      "Epoch 10/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7797 - loss: 0.5882 - val_accuracy: 0.7920 - val_loss: 0.5905\n",
      "Epoch 11/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7911 - loss: 0.5732 - val_accuracy: 0.8040 - val_loss: 0.5641\n",
      "Epoch 12/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7932 - loss: 0.5629 - val_accuracy: 0.7980 - val_loss: 0.5432\n",
      "Epoch 13/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7989 - loss: 0.5493 - val_accuracy: 0.8320 - val_loss: 0.5094\n",
      "Epoch 14/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.5285 - val_accuracy: 0.8140 - val_loss: 0.5297\n",
      "Epoch 15/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.5145 - val_accuracy: 0.8210 - val_loss: 0.5088\n",
      "Epoch 16/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 0.5104 - val_accuracy: 0.8450 - val_loss: 0.4755\n",
      "Epoch 17/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.4953 - val_accuracy: 0.8110 - val_loss: 0.5007\n",
      "Epoch 18/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8190 - loss: 0.5061 - val_accuracy: 0.8450 - val_loss: 0.4633\n",
      "Epoch 19/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.4743 - val_accuracy: 0.8140 - val_loss: 0.5167\n",
      "Epoch 20/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8245 - loss: 0.4791 - val_accuracy: 0.8520 - val_loss: 0.4432\n",
      "Epoch 21/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.4628 - val_accuracy: 0.8450 - val_loss: 0.4465\n",
      "Epoch 22/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.4651 - val_accuracy: 0.8520 - val_loss: 0.4355\n",
      "Epoch 23/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8367 - loss: 0.4581 - val_accuracy: 0.8480 - val_loss: 0.4447\n",
      "Epoch 24/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8497 - loss: 0.4314 - val_accuracy: 0.8450 - val_loss: 0.4496\n",
      "Epoch 25/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4380 - val_accuracy: 0.8420 - val_loss: 0.4702\n",
      "Epoch 26/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.4450 - val_accuracy: 0.8580 - val_loss: 0.4165\n",
      "Epoch 27/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8457 - loss: 0.4365 - val_accuracy: 0.8620 - val_loss: 0.4275\n",
      "Epoch 28/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8460 - loss: 0.4285 - val_accuracy: 0.8550 - val_loss: 0.4235\n",
      "Epoch 29/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.4394 - val_accuracy: 0.8590 - val_loss: 0.4280\n",
      "Epoch 30/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8468 - loss: 0.4253 - val_accuracy: 0.8490 - val_loss: 0.4296\n",
      "uint8\n",
      "(2000, 28, 28)\n",
      "float32\n",
      "(2000, 28, 28)\n",
      "評価用データ\n",
      "0.0 - 1.0\n",
      "0 - 9\n",
      "検証用 [9 2 1 ... 3 6 0] 2000\n",
      "検証用 [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]] 2000\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8315 - loss: 0.4740  \n",
      "Test Loss :  0.47568845748901367\n",
      "Test Accuracy :  0.828499972820282\n"
     ]
    }
   ],
   "source": [
    "# ニューラルネットワークの構成----------------------------\n",
    "# Neural Network\n",
    "img_row = 28                # 入力層のユニット数\n",
    "img_col = 28\n",
    "unit_middle1 = 256          # 中間層のユニット数\n",
    "unit_middle2 = 128\n",
    "unit_output = 10            # 出力層のユニット数\n",
    "learning_rate = 0.1         # 学習係数\n",
    "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
    "batch_size = 64             # ミニバッチのサイズ\n",
    "\n",
    "\n",
    "# ニューラルネットワークの構築-----------------------------\n",
    "# keras.modelsからSequentialをインポート\n",
    "from tensorflow.keras.models import Sequential\n",
    "# keras.layersからDenseとFlattenをインポート\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "# keras.optimizersからSGDをインポート\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Flatten(input_shape = (img_row, img_col)))\n",
    "\n",
    "# 中間層\n",
    "model.add(Dense(unit_middle1, activation = \"sigmoid\"))\n",
    "model.add(Dense(unit_middle2, activation = \"sigmoid\"))\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(unit_output, activation = \"softmax\"))\n",
    "\n",
    "# モデルの概要を出力\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# モデルのコンパイル---------------------------------\n",
    "model.compile(\n",
    "    optimizer = SGD(learning_rate),            # SGD\n",
    "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
    "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
    ")\n",
    "\n",
    "\n",
    "# 学習を実行し、結果を出力する\n",
    "print(train_data1.shape, train_label1.shape)\n",
    "print(valid_data1.shape, valid_label1.shape)\n",
    "history = model.fit(train_data1,\n",
    "                    train_label1,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (valid_data1, valid_label1)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 検証-----------------------------------------------\n",
    "# データ抽出\n",
    "test_data0 = test_data[0:2000, : , : ]\n",
    "test_label0 = test_label[0:2000]\n",
    "\n",
    "# データ型\n",
    "print(test_data0.dtype)\n",
    "print(test_data0.shape)\n",
    "\n",
    "# uint8 -> float32\n",
    "test_data1 = test_data0.astype(\"float32\") / 255\n",
    "\n",
    "# データ型\n",
    "print(test_data1.dtype)\n",
    "print(test_data1.shape)\n",
    "\n",
    "print(\"評価用データ\")\n",
    "print(test_data1.min(), \"-\", test_data1.max())\n",
    "print(test_label0.min(), \"-\", test_label0.max())\n",
    "\n",
    "\n",
    "# ラベルの表示\n",
    "print(\"検証用\", test_label0, len(test_label0))\n",
    "\n",
    "# one-hot vector\n",
    "test_label1 = to_categorical(test_label0)\n",
    "print(\"検証用\", test_label1, len(test_label1))\n",
    "\n",
    "\n",
    "# 検証\n",
    "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
    "# 検証用データの誤り率\n",
    "print(\"Test Loss : \", score[0])\n",
    "# 検証用データの正確度\n",
    "print(\"Test Accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhaooPJscJaK"
   },
   "source": [
    "## ドロップアウト\n",
    "ドロップアウトは過学習を抑制する仕組みの一つで、ネットワークの層におけるユニットの一部がepochごとにランダムに削除されます。model.add()でドロップアウトを追加し、ユニットの削除割合を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BsQX0MsxcF0L",
    "outputId": "1d5b3327-b368-4331-e1c8-7a1b48e7a457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(10000, 28, 28) (10000, 10)\n",
      "(1000, 28, 28) (1000, 10)\n",
      "Epoch 1/30\n",
      "157/157 [==============================] - 2s 6ms/step - loss: 2.2463 - accuracy: 0.1699 - val_loss: 1.8190 - val_accuracy: 0.4020\n",
      "Epoch 2/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.6969 - accuracy: 0.3393 - val_loss: 1.3781 - val_accuracy: 0.4390\n",
      "Epoch 3/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4013 - accuracy: 0.4400 - val_loss: 1.1393 - val_accuracy: 0.6580\n",
      "Epoch 4/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2464 - accuracy: 0.4995 - val_loss: 1.0325 - val_accuracy: 0.6320\n",
      "Epoch 5/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1328 - accuracy: 0.5499 - val_loss: 0.9455 - val_accuracy: 0.6380\n",
      "Epoch 6/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0697 - accuracy: 0.5799 - val_loss: 0.8758 - val_accuracy: 0.6550\n",
      "Epoch 7/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.0053 - accuracy: 0.6055 - val_loss: 0.8294 - val_accuracy: 0.6780\n",
      "Epoch 8/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9551 - accuracy: 0.6250 - val_loss: 0.7824 - val_accuracy: 0.7190\n",
      "Epoch 9/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.9147 - accuracy: 0.6448 - val_loss: 0.7372 - val_accuracy: 0.7090\n",
      "Epoch 10/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8834 - accuracy: 0.6538 - val_loss: 0.7086 - val_accuracy: 0.7420\n",
      "Epoch 11/30\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.8553 - accuracy: 0.6668 - val_loss: 0.6831 - val_accuracy: 0.7440\n",
      "Epoch 12/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.8275 - accuracy: 0.6848 - val_loss: 0.6643 - val_accuracy: 0.7410\n",
      "Epoch 13/30\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.8083 - accuracy: 0.6914 - val_loss: 0.6494 - val_accuracy: 0.7550\n",
      "Epoch 14/30\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.7822 - accuracy: 0.6972 - val_loss: 0.6293 - val_accuracy: 0.7640\n",
      "Epoch 15/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7736 - accuracy: 0.7062 - val_loss: 0.6209 - val_accuracy: 0.7660\n",
      "Epoch 16/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7665 - accuracy: 0.7096 - val_loss: 0.6097 - val_accuracy: 0.7710\n",
      "Epoch 17/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7478 - accuracy: 0.7108 - val_loss: 0.6016 - val_accuracy: 0.7650\n",
      "Epoch 18/30\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.7369 - accuracy: 0.7162 - val_loss: 0.5917 - val_accuracy: 0.7560\n",
      "Epoch 19/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7277 - accuracy: 0.7241 - val_loss: 0.5852 - val_accuracy: 0.7820\n",
      "Epoch 20/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7255 - accuracy: 0.7211 - val_loss: 0.5835 - val_accuracy: 0.7750\n",
      "Epoch 21/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.7183 - accuracy: 0.7242 - val_loss: 0.5751 - val_accuracy: 0.7820\n",
      "Epoch 22/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.7078 - accuracy: 0.7293 - val_loss: 0.5888 - val_accuracy: 0.7800\n",
      "Epoch 23/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6995 - accuracy: 0.7325 - val_loss: 0.5720 - val_accuracy: 0.7860\n",
      "Epoch 24/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6948 - accuracy: 0.7362 - val_loss: 0.5656 - val_accuracy: 0.7930\n",
      "Epoch 25/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6884 - accuracy: 0.7397 - val_loss: 0.5584 - val_accuracy: 0.7830\n",
      "Epoch 26/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6752 - accuracy: 0.7464 - val_loss: 0.5548 - val_accuracy: 0.7860\n",
      "Epoch 27/30\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.6664 - accuracy: 0.7452 - val_loss: 0.5429 - val_accuracy: 0.8080\n",
      "Epoch 28/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6601 - accuracy: 0.7500 - val_loss: 0.5330 - val_accuracy: 0.8110\n",
      "Epoch 29/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.7502 - val_loss: 0.5340 - val_accuracy: 0.8090\n",
      "Epoch 30/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6510 - accuracy: 0.7574 - val_loss: 0.5318 - val_accuracy: 0.8040\n",
      "uint8\n",
      "(2000, 28, 28)\n",
      "float32\n",
      "(2000, 28, 28)\n",
      "評価用データ\n",
      "0.0 - 1.0\n",
      "0 - 9\n",
      "検証用 [9 2 1 ... 3 6 0] 2000\n",
      "検証用 [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]] 2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7740\n",
      "Test Loss :  0.5694349408149719\n",
      "Test Accuracy :  0.7739999890327454\n"
     ]
    }
   ],
   "source": [
    "# ニューラルネットワークの構成----------------------------\n",
    "# Neural Network\n",
    "img_row = 28                # 入力層のユニット数\n",
    "img_col = 28\n",
    "unit_middle1 = 256          # 中間層のユニット数\n",
    "unit_middle2 = 128\n",
    "unit_output = 10            # 出力層のユニット数\n",
    "learning_rate = 0.1         # 学習係数\n",
    "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
    "batch_size = 64             # ミニバッチのサイズ\n",
    "\n",
    "\n",
    "# ニューラルネットワークの構築-----------------------------\n",
    "# keras.modelsからSequentialをインポート\n",
    "from tensorflow.keras.models import Sequential\n",
    "# keras.layersからDenseとFlattenをインポート\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout     # Dropoutを追加\n",
    "# keras.optimizersからSGDをインポート\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Flatten(input_shape = (img_row, img_col)))\n",
    "\n",
    "# 中間層\n",
    "model.add(Dense(unit_middle1, activation = \"sigmoid\"))    # 中間層1\n",
    "model.add(Dropout(0.5))                                   # 中間層でドロップアウト\n",
    "model.add(Dense(unit_middle2, activation = \"sigmoid\"))    # 中間層2\n",
    "model.add(Dropout(0.5))                                   # 中間層でドロップアウト\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(unit_output, activation = \"softmax\"))\n",
    "\n",
    "# モデルの概要を出力\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# モデルのコンパイル---------------------------------\n",
    "model.compile(\n",
    "    optimizer = SGD(learning_rate),            # SGD\n",
    "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
    "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
    ")\n",
    "\n",
    "\n",
    "# 学習を実行し、結果を出力する\n",
    "print(train_data1.shape, train_label1.shape)\n",
    "print(valid_data1.shape, valid_label1.shape)\n",
    "history = model.fit(train_data1,\n",
    "                    train_label1,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (valid_data1, valid_label1)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 検証-----------------------------------------------\n",
    "# データ抽出\n",
    "test_data0 = test_data[0:2000, : , : ]\n",
    "test_label0 = test_label[0:2000]\n",
    "\n",
    "# データ型\n",
    "print(test_data0.dtype)\n",
    "print(test_data0.shape)\n",
    "\n",
    "# uint8 -> float32\n",
    "test_data1 = test_data0.astype(\"float32\") / 255\n",
    "\n",
    "# データ型\n",
    "print(test_data1.dtype)\n",
    "print(test_data1.shape)\n",
    "\n",
    "print(\"評価用データ\")\n",
    "print(test_data1.min(), \"-\", test_data1.max())\n",
    "print(test_label0.min(), \"-\", test_label0.max())\n",
    "\n",
    "\n",
    "# ラベルの表示\n",
    "print(\"検証用\", test_label0, len(test_label0))\n",
    "\n",
    "# one-hot vector\n",
    "test_label1 = to_categorical(test_label0)\n",
    "print(\"検証用\", test_label1, len(test_label1))\n",
    "\n",
    "\n",
    "# 検証\n",
    "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
    "# 検証用データの誤り率\n",
    "print(\"Test Loss : \", score[0])\n",
    "# 検証用データの正確度\n",
    "print(\"Test Accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCquXF_HQbyC"
   },
   "source": [
    "## 活性化関数\n",
    "活性化関数は、入力信号の総和を出力信号に変換する関数です。この場合、入力の総和を求めるとき、一般には重みが付けられます。非線形関数が用いられ、先ほどはシグモイド関数が設定されていました。その他によく用いられる活性化関数として、ReLU（Rectified Linear Unit）があります。一応、シグモイド関数とReLU、その微分を図示しておきます。勾配降下法では活性化関数の微分をかける操作を行うのですが、シグモイド関数だとあまり大きな値は取りえません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "t6nm2GESRznw",
    "outputId": "18e1ca69-ad99-40d7-a604-8a1ddb1584a4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sigmoid & ReLU\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Sigmoid\n",
    "def sigmoid_func(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# Sigmoidの導関数\n",
    "def sigmoid_grad(x):\n",
    "    y = sigmoid_func(x)\n",
    "    return (1 - y) * y\n",
    "\n",
    "#ReLU関数\n",
    "def relu_func(x):\n",
    "    return np.maximum(0, x) #0とxを比較して大きい方の数値を返す\n",
    "\n",
    "# ReLUの導関数\n",
    "def relu_grad(x):\n",
    "    return 1 * (x > 0)\n",
    "\n",
    "x = np.arange(-4, 4, 0.01)\n",
    "y_sigmoid = sigmoid_func(x)\n",
    "y_sig_grad = sigmoid_grad(x)\n",
    "z_relu = relu_func(x)\n",
    "z_relu_grad = relu_grad(x)\n",
    "\n",
    "plt.plot(x, y_sigmoid, label = \"Sigmoid\")\n",
    "plt.plot(x, y_sig_grad, label = \"Sigmoid_grad\")\n",
    "plt.plot(x, z_relu, label = \"ReLU\")\n",
    "plt.plot(x, z_relu_grad, label = \"ReLU_grad\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"input\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ioMRWhOYVxS"
   },
   "source": [
    "では、活性化関数をReLUに変更してみましょう。ニューラルネットワークの構成は先のものと同じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSRNE2CfXBny",
    "outputId": "79f77dbb-39dd-41b0-def0-415cd2898d67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28) (10000, 10)\n",
      "(1000, 28, 28) (1000, 10)\n",
      "Epoch 1/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4593 - loss: 1.5052 - val_accuracy: 0.7410 - val_loss: 0.6609\n",
      "Epoch 2/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6927 - loss: 0.8223 - val_accuracy: 0.7120 - val_loss: 0.7535\n",
      "Epoch 3/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.7343 - val_accuracy: 0.7710 - val_loss: 0.5953\n",
      "Epoch 4/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7664 - loss: 0.6338 - val_accuracy: 0.8490 - val_loss: 0.4830\n",
      "Epoch 5/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.6094 - val_accuracy: 0.8540 - val_loss: 0.4452\n",
      "Epoch 6/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7882 - loss: 0.5795 - val_accuracy: 0.8340 - val_loss: 0.4519\n",
      "Epoch 7/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.5543 - val_accuracy: 0.8220 - val_loss: 0.4775\n",
      "Epoch 8/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8023 - loss: 0.5453 - val_accuracy: 0.8560 - val_loss: 0.4230\n",
      "Epoch 9/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.5239 - val_accuracy: 0.8580 - val_loss: 0.4026\n",
      "Epoch 10/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.5018 - val_accuracy: 0.8700 - val_loss: 0.3809\n",
      "Epoch 11/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.4814 - val_accuracy: 0.8730 - val_loss: 0.3654\n",
      "Epoch 12/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.4564 - val_accuracy: 0.8530 - val_loss: 0.4009\n",
      "Epoch 13/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8215 - loss: 0.4891 - val_accuracy: 0.8660 - val_loss: 0.3685\n",
      "Epoch 14/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8317 - loss: 0.4471 - val_accuracy: 0.8480 - val_loss: 0.4044\n",
      "Epoch 15/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8309 - loss: 0.4526 - val_accuracy: 0.8690 - val_loss: 0.3845\n",
      "Epoch 16/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.4240 - val_accuracy: 0.8840 - val_loss: 0.3507\n",
      "Epoch 17/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8434 - loss: 0.4217 - val_accuracy: 0.8670 - val_loss: 0.3753\n",
      "Epoch 18/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.4272 - val_accuracy: 0.8570 - val_loss: 0.3903\n",
      "Epoch 19/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8549 - loss: 0.4166 - val_accuracy: 0.8850 - val_loss: 0.3420\n",
      "Epoch 20/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8512 - loss: 0.4227 - val_accuracy: 0.8780 - val_loss: 0.3564\n",
      "Epoch 21/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8549 - loss: 0.4004 - val_accuracy: 0.8870 - val_loss: 0.3479\n",
      "Epoch 22/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8572 - loss: 0.3969 - val_accuracy: 0.8780 - val_loss: 0.3611\n",
      "Epoch 23/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8510 - loss: 0.3958 - val_accuracy: 0.8730 - val_loss: 0.3680\n",
      "Epoch 24/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8599 - loss: 0.3797 - val_accuracy: 0.8950 - val_loss: 0.3354\n",
      "Epoch 25/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8594 - loss: 0.3879 - val_accuracy: 0.8760 - val_loss: 0.3680\n",
      "Epoch 26/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.3830 - val_accuracy: 0.8580 - val_loss: 0.3897\n",
      "Epoch 27/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.3693 - val_accuracy: 0.8870 - val_loss: 0.3447\n",
      "Epoch 28/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8660 - loss: 0.3670 - val_accuracy: 0.8770 - val_loss: 0.3725\n",
      "Epoch 29/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8606 - loss: 0.3709 - val_accuracy: 0.8870 - val_loss: 0.3502\n",
      "Epoch 30/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.3581 - val_accuracy: 0.8540 - val_loss: 0.4094\n",
      "uint8\n",
      "(2000, 28, 28)\n",
      "float32\n",
      "(2000, 28, 28)\n",
      "評価用データ\n",
      "0.0 - 1.0\n",
      "0 - 9\n",
      "検証用 [9 2 1 ... 3 6 0] 2000\n",
      "検証用 [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]] 2000\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8371 - loss: 0.4927  \n",
      "Test Loss :  0.47178906202316284\n",
      "Test Accuracy :  0.8360000252723694\n"
     ]
    }
   ],
   "source": [
    "# ニューラルネットワークの構成----------------------------\n",
    "# Neural Network\n",
    "img_row = 28                # 入力層のユニット数\n",
    "img_col = 28\n",
    "unit_middle1 = 256          # 中間層のユニット数\n",
    "unit_middle2 = 128\n",
    "unit_output = 10            # 出力層のユニット数\n",
    "learning_rate = 0.1         # 学習係数\n",
    "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
    "batch_size = 64             # ミニバッチのサイズ\n",
    "\n",
    "\n",
    "# ニューラルネットワークの構築-----------------------------\n",
    "# keras.modelsからSequentialをインポート\n",
    "from tensorflow.keras.models import Sequential\n",
    "# keras.layersからDenseとFlattenをインポート\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout     # Dropoutを追加\n",
    "# keras.optimizersからSGDをインポート\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Flatten(input_shape = (img_row, img_col)))\n",
    "\n",
    "# 中間層\n",
    "model.add(Dense(unit_middle1, activation = \"relu\"))    # 中間層1\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "model.add(Dense(unit_middle2, activation = \"relu\"))    # 中間層2\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(unit_output, activation = \"softmax\"))\n",
    "\n",
    "# モデルの概要を出力\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# モデルのコンパイル---------------------------------\n",
    "model.compile(\n",
    "    optimizer = SGD(learning_rate),            # SGD\n",
    "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
    "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
    ")\n",
    "\n",
    "\n",
    "# 学習を実行し、結果を出力する\n",
    "print(train_data1.shape, train_label1.shape)\n",
    "print(valid_data1.shape, valid_label1.shape)\n",
    "history = model.fit(train_data1,\n",
    "                    train_label1,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (valid_data1, valid_label1)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 検証-----------------------------------------------\n",
    "# データ抽出\n",
    "test_data0 = test_data[0:2000, : , : ]\n",
    "test_label0 = test_label[0:2000]\n",
    "\n",
    "# データ型\n",
    "print(test_data0.dtype)\n",
    "print(test_data0.shape)\n",
    "\n",
    "# uint8 -> float32\n",
    "test_data1 = test_data0.astype(\"float32\") / 255\n",
    "\n",
    "# データ型\n",
    "print(test_data1.dtype)\n",
    "print(test_data1.shape)\n",
    "\n",
    "print(\"評価用データ\")\n",
    "print(test_data1.min(), \"-\", test_data1.max())\n",
    "print(test_label0.min(), \"-\", test_label0.max())\n",
    "\n",
    "\n",
    "# ラベルの表示\n",
    "print(\"検証用\", test_label0, len(test_label0))\n",
    "\n",
    "# one-hot vector\n",
    "test_label1 = to_categorical(test_label0)\n",
    "print(\"検証用\", test_label1, len(test_label1))\n",
    "\n",
    "\n",
    "# 検証\n",
    "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
    "# 検証用データの誤り率\n",
    "print(\"Test Loss : \", score[0])\n",
    "# 検証用データの正確度\n",
    "print(\"Test Accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ufms0iFdeGkk"
   },
   "source": [
    "## 最適化関数\n",
    "最適化関数（optimizer）は、損失関数を重みで微分し、学習率や過去の重みの更新量を踏まえて、どのように重みの更新に反映するかを指定します。これまで、SGD（確率的勾配降下法）を設定していました。ここで、Adam（Adaptive Moment Estimation）を使ってみます。Adamは、振動抑制に移動平均するmomentumと、学習係数を調整するRMSPropとを組み合わせたような感じです。\n",
    "tensorflow.keras.optimizersからAdamをインポートし、model.compileのoptimizerに\"Adam\"を指定します。β1は一次モーメントの減衰率、β2は二次モーメントの減衰率です。この場合、学習係数を小さめに取らないと精度が出ません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywTXq4Oug1EW",
    "outputId": "2f84b930-51a1-49ad-d52b-d0cf9f1b795a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28) (10000, 10)\n",
      "(1000, 28, 28) (1000, 10)\n",
      "Epoch 1/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4741 - loss: 1.4881 - val_accuracy: 0.7930 - val_loss: 0.5734\n",
      "Epoch 2/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7272 - loss: 0.7597 - val_accuracy: 0.8300 - val_loss: 0.4824\n",
      "Epoch 3/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7662 - loss: 0.6448 - val_accuracy: 0.8540 - val_loss: 0.4426\n",
      "Epoch 4/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7892 - loss: 0.5835 - val_accuracy: 0.8580 - val_loss: 0.4314\n",
      "Epoch 5/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.5470 - val_accuracy: 0.8330 - val_loss: 0.4422\n",
      "Epoch 6/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8109 - loss: 0.5206 - val_accuracy: 0.8750 - val_loss: 0.3828\n",
      "Epoch 7/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8168 - loss: 0.5025 - val_accuracy: 0.8740 - val_loss: 0.3801\n",
      "Epoch 8/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4540 - val_accuracy: 0.8780 - val_loss: 0.3732\n",
      "Epoch 9/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 0.4698 - val_accuracy: 0.8720 - val_loss: 0.3599\n",
      "Epoch 10/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8433 - loss: 0.4388 - val_accuracy: 0.8890 - val_loss: 0.3480\n",
      "Epoch 11/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.4483 - val_accuracy: 0.8820 - val_loss: 0.3518\n",
      "Epoch 12/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.4252 - val_accuracy: 0.8900 - val_loss: 0.3449\n",
      "Epoch 13/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8495 - loss: 0.4190 - val_accuracy: 0.8810 - val_loss: 0.3480\n",
      "Epoch 14/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8560 - loss: 0.4038 - val_accuracy: 0.8850 - val_loss: 0.3521\n",
      "Epoch 15/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8578 - loss: 0.3935 - val_accuracy: 0.8810 - val_loss: 0.3479\n",
      "Epoch 16/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.3919 - val_accuracy: 0.8820 - val_loss: 0.3446\n",
      "Epoch 17/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8556 - loss: 0.3905 - val_accuracy: 0.8820 - val_loss: 0.3383\n",
      "Epoch 18/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8608 - loss: 0.3636 - val_accuracy: 0.8820 - val_loss: 0.3457\n",
      "Epoch 19/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8631 - loss: 0.3743 - val_accuracy: 0.8830 - val_loss: 0.3416\n",
      "Epoch 20/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8583 - loss: 0.3803 - val_accuracy: 0.8770 - val_loss: 0.3630\n",
      "Epoch 21/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8614 - loss: 0.3631 - val_accuracy: 0.8820 - val_loss: 0.3323\n",
      "Epoch 22/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3678 - val_accuracy: 0.8830 - val_loss: 0.3404\n",
      "Epoch 23/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.3698 - val_accuracy: 0.8800 - val_loss: 0.3415\n",
      "Epoch 24/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.3474 - val_accuracy: 0.8850 - val_loss: 0.3327\n",
      "Epoch 25/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.3373 - val_accuracy: 0.8860 - val_loss: 0.3242\n",
      "Epoch 26/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8772 - loss: 0.3412 - val_accuracy: 0.8780 - val_loss: 0.3563\n",
      "Epoch 27/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8768 - loss: 0.3522 - val_accuracy: 0.8840 - val_loss: 0.3271\n",
      "Epoch 28/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8786 - loss: 0.3307 - val_accuracy: 0.8910 - val_loss: 0.3291\n",
      "Epoch 29/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8751 - loss: 0.3395 - val_accuracy: 0.8840 - val_loss: 0.3341\n",
      "Epoch 30/30\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.3125 - val_accuracy: 0.8930 - val_loss: 0.3315\n",
      "uint8\n",
      "(2000, 28, 28)\n",
      "float32\n",
      "(2000, 28, 28)\n",
      "評価用データ\n",
      "0.0 - 1.0\n",
      "0 - 9\n",
      "検証用 [9 2 1 ... 3 6 0] 2000\n",
      "検証用 [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]] 2000\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8608 - loss: 0.3949  \n",
      "Test Loss :  0.39817485213279724\n",
      "Test Accuracy :  0.8604999780654907\n"
     ]
    }
   ],
   "source": [
    "# ニューラルネットワークの構成----------------------------\n",
    "# Neural Network\n",
    "img_row = 28                # 入力層のユニット数\n",
    "img_col = 28\n",
    "unit_middle1 = 256          # 中間層のユニット数\n",
    "unit_middle2 = 128\n",
    "unit_output = 10            # 出力層のユニット数\n",
    "learning_rate = 0.001         # 学習係数\n",
    "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
    "batch_size = 64             # ミニバッチのサイズ\n",
    "\n",
    "\n",
    "# ニューラルネットワークの構築-----------------------------\n",
    "# keras.modelsからSequentialをインポート\n",
    "from tensorflow.keras.models import Sequential\n",
    "# keras.layersからDenseとFlattenをインポート\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout     # Dropoutを追加\n",
    "# keras.optimizersからSGDをインポート\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Flatten(input_shape = (img_row, img_col)))\n",
    "\n",
    "# 中間層\n",
    "model.add(Dense(unit_middle1, activation = \"relu\"))    # 中間層1\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "model.add(Dense(unit_middle2, activation = \"relu\"))    # 中間層2\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(unit_output, activation = \"softmax\"))\n",
    "\n",
    "# モデルの概要を出力\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# モデルのコンパイル---------------------------------\n",
    "model.compile(\n",
    "    optimizer = Adam(learning_rate, beta_1=0.9, beta_2=0.999),   # Adam\n",
    "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
    "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
    ")\n",
    "\n",
    "\n",
    "# 学習を実行し、結果を出力する\n",
    "print(train_data1.shape, train_label1.shape)\n",
    "print(valid_data1.shape, valid_label1.shape)\n",
    "history = model.fit(train_data1,\n",
    "                    train_label1,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (valid_data1, valid_label1)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 検証-----------------------------------------------\n",
    "# データ抽出\n",
    "test_data0 = test_data[0:2000, : , : ]\n",
    "test_label0 = test_label[0:2000]\n",
    "\n",
    "# データ型\n",
    "print(test_data0.dtype)\n",
    "print(test_data0.shape)\n",
    "\n",
    "# uint8 -> float32\n",
    "test_data1 = test_data0.astype(\"float32\") / 255\n",
    "\n",
    "# データ型\n",
    "print(test_data1.dtype)\n",
    "print(test_data1.shape)\n",
    "\n",
    "print(\"評価用データ\")\n",
    "print(test_data1.min(), \"-\", test_data1.max())\n",
    "print(test_label0.min(), \"-\", test_label0.max())\n",
    "\n",
    "\n",
    "# ラベルの表示\n",
    "print(\"検証用\", test_label0, len(test_label0))\n",
    "\n",
    "# one-hot vector\n",
    "test_label1 = to_categorical(test_label0)\n",
    "print(\"検証用\", test_label1, len(test_label1))\n",
    "\n",
    "\n",
    "# 検証\n",
    "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
    "# 検証用データの誤り率\n",
    "print(\"Test Loss : \", score[0])\n",
    "# 検証用データの正確度\n",
    "print(\"Test Accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdDJotS0kCRl"
   },
   "source": [
    "## 学習係数\n",
    "学習係数は学習率とも呼ばれ、ネットワークの層の重みをどのくらい変更するかを決めるものです。損失関数に対して適切な学習係数を設定することは極めて重要です。Adamの特別な場合がSGDと考えることもできますから、最適化関数を\"SGD\"に戻します。ただし、学習係数を\"0.001\"に設定しています。重みの更新量が少なくなりますので、\"epochs = 30\"では収束しきらないようです（収束に時間がかかる）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44FT54GcqbHg",
    "outputId": "30f3ce10-acf8-474f-f0f9-595b72b1a1ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(10000, 28, 28) (10000, 10)\n",
      "(1000, 28, 28) (1000, 10)\n",
      "Epoch 1/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.4042 - accuracy: 0.1302 - val_loss: 2.1255 - val_accuracy: 0.2770\n",
      "Epoch 2/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.2025 - accuracy: 0.1824 - val_loss: 1.9912 - val_accuracy: 0.4050\n",
      "Epoch 3/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.0805 - accuracy: 0.2400 - val_loss: 1.8855 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.9878 - accuracy: 0.2817 - val_loss: 1.7911 - val_accuracy: 0.5430\n",
      "Epoch 5/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.9169 - accuracy: 0.3225 - val_loss: 1.7076 - val_accuracy: 0.5730\n",
      "Epoch 6/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.8412 - accuracy: 0.3543 - val_loss: 1.6279 - val_accuracy: 0.5900\n",
      "Epoch 7/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7624 - accuracy: 0.3924 - val_loss: 1.5532 - val_accuracy: 0.5960\n",
      "Epoch 8/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.7209 - accuracy: 0.3995 - val_loss: 1.4883 - val_accuracy: 0.6090\n",
      "Epoch 9/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6622 - accuracy: 0.4207 - val_loss: 1.4259 - val_accuracy: 0.6240\n",
      "Epoch 10/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.6039 - accuracy: 0.4388 - val_loss: 1.3696 - val_accuracy: 0.6270\n",
      "Epoch 11/30\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.5779 - accuracy: 0.4463 - val_loss: 1.3205 - val_accuracy: 0.6280\n",
      "Epoch 12/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.5441 - accuracy: 0.4551 - val_loss: 1.2756 - val_accuracy: 0.6390\n",
      "Epoch 13/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4953 - accuracy: 0.4800 - val_loss: 1.2333 - val_accuracy: 0.6420\n",
      "Epoch 14/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4586 - accuracy: 0.4803 - val_loss: 1.1941 - val_accuracy: 0.6440\n",
      "Epoch 15/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.4324 - accuracy: 0.4983 - val_loss: 1.1596 - val_accuracy: 0.6520\n",
      "Epoch 16/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3960 - accuracy: 0.5070 - val_loss: 1.1260 - val_accuracy: 0.6570\n",
      "Epoch 17/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3821 - accuracy: 0.5051 - val_loss: 1.0961 - val_accuracy: 0.6620\n",
      "Epoch 18/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3445 - accuracy: 0.5214 - val_loss: 1.0705 - val_accuracy: 0.6640\n",
      "Epoch 19/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.3262 - accuracy: 0.5215 - val_loss: 1.0459 - val_accuracy: 0.6680\n",
      "Epoch 20/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2945 - accuracy: 0.5369 - val_loss: 1.0215 - val_accuracy: 0.6700\n",
      "Epoch 21/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2811 - accuracy: 0.5447 - val_loss: 1.0013 - val_accuracy: 0.6760\n",
      "Epoch 22/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2481 - accuracy: 0.5600 - val_loss: 0.9795 - val_accuracy: 0.6910\n",
      "Epoch 23/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2240 - accuracy: 0.5586 - val_loss: 0.9606 - val_accuracy: 0.6880\n",
      "Epoch 24/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2199 - accuracy: 0.5620 - val_loss: 0.9445 - val_accuracy: 0.6930\n",
      "Epoch 25/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.2088 - accuracy: 0.5639 - val_loss: 0.9301 - val_accuracy: 0.6970\n",
      "Epoch 26/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1958 - accuracy: 0.5718 - val_loss: 0.9172 - val_accuracy: 0.7030\n",
      "Epoch 27/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1709 - accuracy: 0.5824 - val_loss: 0.9027 - val_accuracy: 0.7080\n",
      "Epoch 28/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1592 - accuracy: 0.5840 - val_loss: 0.8907 - val_accuracy: 0.7100\n",
      "Epoch 29/30\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.1461 - accuracy: 0.5869 - val_loss: 0.8797 - val_accuracy: 0.7160\n",
      "Epoch 30/30\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.1282 - accuracy: 0.5954 - val_loss: 0.8676 - val_accuracy: 0.7140\n",
      "uint8\n",
      "(2000, 28, 28)\n",
      "float32\n",
      "(2000, 28, 28)\n",
      "評価用データ\n",
      "0.0 - 1.0\n",
      "0 - 9\n",
      "検証用 [9 2 1 ... 3 6 0] 2000\n",
      "検証用 [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]] 2000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8878 - accuracy: 0.7015\n",
      "Test Loss :  0.8877738118171692\n",
      "Test Accuracy :  0.7014999985694885\n"
     ]
    }
   ],
   "source": [
    "# ニューラルネットワークの構成----------------------------\n",
    "# Neural Network\n",
    "img_row = 28                # 入力層のユニット数\n",
    "img_col = 28\n",
    "unit_middle1 = 256          # 中間層のユニット数\n",
    "unit_middle2 = 128\n",
    "unit_output = 10            # 出力層のユニット数\n",
    "learning_rate = 0.001         # 学習係数\n",
    "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
    "batch_size = 64             # ミニバッチのサイズ\n",
    "\n",
    "\n",
    "# ニューラルネットワークの構築-----------------------------\n",
    "# keras.modelsからSequentialをインポート\n",
    "from tensorflow.keras.models import Sequential\n",
    "# keras.layersからDenseとFlattenをインポート\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout     # Dropoutを追加\n",
    "# keras.optimizersからSGDをインポート\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Flatten(input_shape = (img_row, img_col)))\n",
    "\n",
    "# 中間層\n",
    "model.add(Dense(unit_middle1, activation = \"relu\"))    # 中間層1\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "model.add(Dense(unit_middle2, activation = \"relu\"))    # 中間層2\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(unit_output, activation = \"softmax\"))\n",
    "\n",
    "# モデルの概要を出力\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# モデルのコンパイル---------------------------------\n",
    "model.compile(\n",
    "    optimizer = SGD(learning_rate),            # SGD\n",
    "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
    "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
    ")\n",
    "\n",
    "\n",
    "# 学習を実行し、結果を出力する\n",
    "print(train_data1.shape, train_label1.shape)\n",
    "print(valid_data1.shape, valid_label1.shape)\n",
    "history = model.fit(train_data1,\n",
    "                    train_label1,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (valid_data1, valid_label1)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 検証-----------------------------------------------\n",
    "# データ抽出\n",
    "test_data0 = test_data[0:2000, : , : ]\n",
    "test_label0 = test_label[0:2000]\n",
    "\n",
    "# データ型\n",
    "print(test_data0.dtype)\n",
    "print(test_data0.shape)\n",
    "\n",
    "# uint8 -> float32\n",
    "test_data1 = test_data0.astype(\"float32\") / 255\n",
    "\n",
    "# データ型\n",
    "print(test_data1.dtype)\n",
    "print(test_data1.shape)\n",
    "\n",
    "print(\"評価用データ\")\n",
    "print(test_data1.min(), \"-\", test_data1.max())\n",
    "print(test_label0.min(), \"-\", test_label0.max())\n",
    "\n",
    "\n",
    "# ラベルの表示\n",
    "print(\"検証用\", test_label0, len(test_label0))\n",
    "\n",
    "# one-hot vector\n",
    "test_label1 = to_categorical(test_label0)\n",
    "print(\"検証用\", test_label1, len(test_label1))\n",
    "\n",
    "\n",
    "# 検証\n",
    "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
    "# 検証用データの誤り率\n",
    "print(\"Test Loss : \", score[0])\n",
    "# 検証用データの正確度\n",
    "print(\"Test Accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZPI4txXq-cx"
   },
   "source": [
    "## ミニバッチ学習\n",
    "ニューラルネットワークのモデルを学習するとき、モデルに与える学習データの数をバッチサイズといいます。このバッチサイズで学習（ミニバッチ学習）を行い、損失関数の勾配を求めて重みの更新を行います。バッチサイズの難しさは他のパラメータと関係している点にあります。バッチサイズは主に、データ1個に対する感度、1エポックの計算時間、メモリ使用量にきいてきます。バッチサイズが小さいと、1つのデータに反応しやすくなります（この場合、学習係数を調整する）。バッチサイズが大きいと、データ全体の特徴を捉える感じになります。バッチサイズが小さいと、重み更新の回数は多くなりますから計算時間はかかります。バッチサイズの単位でデータを読みますから、バッチサイズが小さい方が、メモリ使用量は少なくて済みます。以下ではバッチサイズを\"batch_size = 32\"に設定します（学習係数は\"0.1\"に戻す）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zcoZdX7y_lT",
    "outputId": "0ab96ef2-6f48-4ed9-f825-14c1766a2a79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(10000, 28, 28) (10000, 10)\n",
      "(1000, 28, 28) (1000, 10)\n",
      "Epoch 1/30\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 1.0662 - accuracy: 0.6122 - val_loss: 0.6628 - val_accuracy: 0.7350\n",
      "Epoch 2/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7406 - accuracy: 0.7255 - val_loss: 0.5094 - val_accuracy: 0.8070\n",
      "Epoch 3/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6556 - accuracy: 0.7588 - val_loss: 0.4594 - val_accuracy: 0.8420\n",
      "Epoch 4/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6124 - accuracy: 0.7756 - val_loss: 0.4690 - val_accuracy: 0.8370\n",
      "Epoch 5/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5772 - accuracy: 0.7874 - val_loss: 0.4251 - val_accuracy: 0.8540\n",
      "Epoch 6/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5598 - accuracy: 0.7982 - val_loss: 0.4477 - val_accuracy: 0.8160\n",
      "Epoch 7/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5277 - accuracy: 0.8069 - val_loss: 0.4195 - val_accuracy: 0.8390\n",
      "Epoch 8/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5148 - accuracy: 0.8086 - val_loss: 0.4840 - val_accuracy: 0.8180\n",
      "Epoch 9/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4915 - accuracy: 0.8196 - val_loss: 0.3880 - val_accuracy: 0.8770\n",
      "Epoch 10/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4859 - accuracy: 0.8217 - val_loss: 0.3882 - val_accuracy: 0.8550\n",
      "Epoch 11/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4659 - accuracy: 0.8303 - val_loss: 0.3707 - val_accuracy: 0.8800\n",
      "Epoch 12/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4654 - accuracy: 0.8293 - val_loss: 0.3864 - val_accuracy: 0.8740\n",
      "Epoch 13/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4531 - accuracy: 0.8357 - val_loss: 0.4487 - val_accuracy: 0.8180\n",
      "Epoch 14/30\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.4420 - accuracy: 0.8376 - val_loss: 0.3792 - val_accuracy: 0.8730\n",
      "Epoch 15/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4412 - accuracy: 0.8341 - val_loss: 0.3922 - val_accuracy: 0.8710\n",
      "Epoch 16/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4385 - accuracy: 0.8416 - val_loss: 0.3680 - val_accuracy: 0.8740\n",
      "Epoch 17/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4182 - accuracy: 0.8464 - val_loss: 0.3625 - val_accuracy: 0.8810\n",
      "Epoch 18/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4172 - accuracy: 0.8443 - val_loss: 0.3576 - val_accuracy: 0.8820\n",
      "Epoch 19/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4073 - accuracy: 0.8467 - val_loss: 0.3564 - val_accuracy: 0.8760\n",
      "Epoch 20/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4003 - accuracy: 0.8511 - val_loss: 0.3739 - val_accuracy: 0.8760\n",
      "Epoch 21/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4097 - accuracy: 0.8516 - val_loss: 0.3971 - val_accuracy: 0.8560\n",
      "Epoch 22/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3962 - accuracy: 0.8533 - val_loss: 0.3573 - val_accuracy: 0.8850\n",
      "Epoch 23/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3934 - accuracy: 0.8514 - val_loss: 0.4244 - val_accuracy: 0.8540\n",
      "Epoch 24/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3874 - accuracy: 0.8571 - val_loss: 0.3760 - val_accuracy: 0.8690\n",
      "Epoch 25/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3839 - accuracy: 0.8592 - val_loss: 0.3514 - val_accuracy: 0.8780\n",
      "Epoch 26/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3825 - accuracy: 0.8554 - val_loss: 0.3563 - val_accuracy: 0.8780\n",
      "Epoch 27/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3735 - accuracy: 0.8604 - val_loss: 0.3554 - val_accuracy: 0.8840\n",
      "Epoch 28/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3617 - accuracy: 0.8683 - val_loss: 0.3899 - val_accuracy: 0.8690\n",
      "Epoch 29/30\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3578 - accuracy: 0.8659 - val_loss: 0.4115 - val_accuracy: 0.8680\n",
      "Epoch 30/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3661 - accuracy: 0.8661 - val_loss: 0.3418 - val_accuracy: 0.8830\n",
      "uint8\n",
      "(2000, 28, 28)\n",
      "float32\n",
      "(2000, 28, 28)\n",
      "評価用データ\n",
      "0.0 - 1.0\n",
      "0 - 9\n",
      "検証用 [9 2 1 ... 3 6 0] 2000\n",
      "検証用 [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]] 2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8670\n",
      "Test Loss :  0.38915807008743286\n",
      "Test Accuracy :  0.8669999837875366\n"
     ]
    }
   ],
   "source": [
    "# ニューラルネットワークの構成----------------------------\n",
    "# Neural Network\n",
    "img_row = 28                # 入力層のユニット数\n",
    "img_col = 28\n",
    "unit_middle1 = 256          # 中間層のユニット数\n",
    "unit_middle2 = 128\n",
    "unit_output = 10            # 出力層のユニット数\n",
    "learning_rate = 0.1         # 学習係数\n",
    "epochs = 30                 # 学習を繰り返す回数（エポック数）\n",
    "batch_size = 32             # ミニバッチのサイズ\n",
    "\n",
    "\n",
    "# ニューラルネットワークの構築-----------------------------\n",
    "# keras.modelsからSequentialをインポート\n",
    "from tensorflow.keras.models import Sequential\n",
    "# keras.layersからDenseとFlattenをインポート\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout     # Dropoutを追加\n",
    "# keras.optimizersからSGDをインポート\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Flatten(input_shape = (img_row, img_col)))\n",
    "\n",
    "# 中間層\n",
    "model.add(Dense(unit_middle1, activation = \"relu\"))    # 中間層1\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "model.add(Dense(unit_middle2, activation = \"relu\"))    # 中間層2\n",
    "model.add(Dropout(0.5))                                # 中間層でドロップアウト\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(unit_output, activation = \"softmax\"))\n",
    "\n",
    "# モデルの概要を出力\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# モデルのコンパイル---------------------------------\n",
    "model.compile(\n",
    "    optimizer = SGD(learning_rate),            # SGD\n",
    "    loss = \"categorical_crossentropy\",         # 交差エントロピー誤差\n",
    "    metrics = [\"accuracy\"]                     # 学習評価の指標はaccuracy\n",
    ")\n",
    "\n",
    "\n",
    "# 学習を実行し、結果を出力する\n",
    "print(train_data1.shape, train_label1.shape)\n",
    "print(valid_data1.shape, valid_label1.shape)\n",
    "history = model.fit(train_data1,\n",
    "                    train_label1,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (valid_data1, valid_label1)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 検証-----------------------------------------------\n",
    "# データ抽出\n",
    "test_data0 = test_data[0:2000, : , : ]\n",
    "test_label0 = test_label[0:2000]\n",
    "\n",
    "# データ型\n",
    "print(test_data0.dtype)\n",
    "print(test_data0.shape)\n",
    "\n",
    "# uint8 -> float32\n",
    "test_data1 = test_data0.astype(\"float32\") / 255\n",
    "\n",
    "# データ型\n",
    "print(test_data1.dtype)\n",
    "print(test_data1.shape)\n",
    "\n",
    "print(\"評価用データ\")\n",
    "print(test_data1.min(), \"-\", test_data1.max())\n",
    "print(test_label0.min(), \"-\", test_label0.max())\n",
    "\n",
    "\n",
    "# ラベルの表示\n",
    "print(\"検証用\", test_label0, len(test_label0))\n",
    "\n",
    "# one-hot vector\n",
    "test_label1 = to_categorical(test_label0)\n",
    "print(\"検証用\", test_label1, len(test_label1))\n",
    "\n",
    "\n",
    "# 検証\n",
    "score = model.evaluate(test_data1, test_label1, verbose = 1)\n",
    "# 検証用データの誤り率\n",
    "print(\"Test Loss : \", score[0])\n",
    "# 検証用データの正確度\n",
    "print(\"Test Accuracy : \", score[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
